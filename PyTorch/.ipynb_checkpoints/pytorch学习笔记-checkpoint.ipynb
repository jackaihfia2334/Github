{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31699c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "a = t.arange(12).view(3,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0164a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[t.tensor([1, 2]), t.tensor([0, 2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a85633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  8],\n",
       "        [ 6, 10]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[t.tensor([1,2])[None,:], t.tensor([0, 2])[:,None]] # 不相同形状的index索引，满足广播法则\n",
    "                                                     # 获取索引为[1,0]、[2,0]、[1,2]、[2,2]的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67ef25ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2]]),\n",
       " tensor([[0],\n",
       "         [2]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tensor([1,2])[None,:], t.tensor([0, 2])[:,None]   #先广播法则扩展，再索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a2f0ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8,  9, 10, 11],\n",
      "        [ 0,  1,  2,  3]])\n"
     ]
    }
   ],
   "source": [
    "print(a[[2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a431b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7, 10,  1])\n"
     ]
    }
   ],
   "source": [
    "print(a[[1, 2, 0], [3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbc3535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, -3,  2],\n",
      "        [ 2,  9, -1],\n",
      "        [-8,  4,  1]])\n",
      "tensor([[ 2, -3,  4],\n",
      "        [ 4, 18, -1],\n",
      "        [-8,  8,  2]])\n"
     ]
    }
   ],
   "source": [
    "b = t.tensor([[1, -3, 2], [2, 9, -1], [-8, 4, 1]])\n",
    "print(b)\n",
    "b[b > 0] *= 2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aebac351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([[[1, 3, 3, 5],\n",
      "         [5, 4, 5, 1],\n",
      "         [4, 5, 2, 5]],\n",
      "\n",
      "        [[6, 8, 0, 1],\n",
      "         [3, 8, 1, 8],\n",
      "         [1, 4, 6, 5]],\n",
      "\n",
      "        [[3, 1, 4, 3],\n",
      "         [5, 7, 5, 6],\n",
      "         [7, 6, 1, 4]],\n",
      "\n",
      "        [[3, 2, 5, 4],\n",
      "         [6, 7, 8, 2],\n",
      "         [4, 0, 8, 3]],\n",
      "\n",
      "        [[2, 5, 4, 5],\n",
      "         [4, 6, 3, 6],\n",
      "         [4, 4, 8, 1]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机生成一组形状为(5,3,4)、0~9数字组成的张量\n",
    "a = t.randint(1, 10, (5,3,4))\n",
    "# 获取输出的unique list和索引\n",
    "output, inverse_indices = t.unique(a, return_inverse=True)\n",
    "print(output)\n",
    "print(inverse_indices)\n",
    "# 通过整数数组索引 还原原始tensor\n",
    "a_generate = output[inverse_indices]\n",
    "a_generate.equal(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6c8192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 2, 1, 9, 3, 4, 7]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9, 3, 2, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.randint(1, 10, (1,7))\n",
    "print(x)\n",
    "x[:,t.tensor([3,4,1,2])]  #  整数数组索引，输出的size等于索引的size，可以大于x本身的size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412061c",
   "metadata": {},
   "source": [
    "# nn.embedding学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e4e6eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "tensor([[1, 2],\n",
      "        [4, 2],\n",
      "        [4, 1],\n",
      "        [3, 2]])\n",
      "----------------------------------------------------------------------\n",
      "torch.Size([4, 2, 6])\n",
      "tensor([[[-0.4663,  0.5425,  0.0533, -1.5261,  0.3110,  0.1871],\n",
      "         [-1.0019, -1.4731,  0.5315, -0.0386,  2.1083,  0.2508]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.0019, -1.4731,  0.5315, -0.0386,  2.1083,  0.2508]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.4663,  0.5425,  0.0533, -1.5261,  0.3110,  0.1871]],\n",
      "\n",
      "        [[ 2.3033, -0.0814, -0.1821, -1.6813, -1.2886, -0.6068],\n",
      "         [-1.0019, -1.4731,  0.5315, -0.0386,  2.1083,  0.2508]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# 输入\n",
    "x = torch.LongTensor([[1, 2], [4, 2],[4, 1],[3, 2]])\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "# 调用nn.Embedding函数\n",
    "# 一共5个词，每个词的词向量维度设置为6维\n",
    "embeddings = nn.Embedding(5, 6, padding_idx=4)\n",
    "print(embeddings(x).shape)\n",
    "print(embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ddc476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T14:14:24.765945Z",
     "start_time": "2023-05-15T14:14:24.746980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[1, 2, 4, 5],\n",
      "        [4, 2, 3, 5]])\n",
      "----------------------------------------------------------------------\n",
      "torch.Size([2, 4, 8])\n",
      "tensor([[[ 0.9314,  0.5311,  0.6459, -1.2578,  0.4871,  0.4457, -0.1483,\n",
      "           0.6271],\n",
      "         [-0.8089,  0.7538, -0.1759, -0.3989, -0.9927,  0.5860,  0.4551,\n",
      "           1.0254],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000],\n",
      "         [ 0.1241, -1.4762,  0.5173, -0.5091, -0.8977,  0.3745, -0.1958,\n",
      "          -0.5423]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000],\n",
      "         [-0.8089,  0.7538, -0.1759, -0.3989, -0.9927,  0.5860,  0.4551,\n",
      "           1.0254],\n",
      "         [-0.2314, -0.7900,  0.3709, -0.9600, -0.1549,  0.9504, -0.5565,\n",
      "           1.0131],\n",
      "         [ 0.1241, -1.4762,  0.5173, -0.5091, -0.8977,  0.3745, -0.1958,\n",
      "          -0.5423]]], grad_fn=<EmbeddingBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 2.0000, 0.0000, 2.0000],\n",
       "        [0.0000, 2.0000, 2.0000, 2.0000]], grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.LongTensor([[1, 2,4,5], [4,2,3,5]])\n",
    "print(x.shape)\n",
    "print(x)\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "embeddings = nn.Embedding(6, 8, padding_idx=4,max_norm=2)\n",
    "emb = embeddings(x)\n",
    "print(emb.shape)\n",
    "print(emb)\n",
    "torch.norm(emb,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99e6434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T14:14:48.694127Z",
     "start_time": "2023-05-15T14:14:48.686120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0861, -0.4704,  0.6897,  0.6285, -0.0637, -0.4674, -1.5227, -2.5396],\n",
       "        [ 0.9314,  0.5311,  0.6459, -1.2578,  0.4871,  0.4457, -0.1483,  0.6271],\n",
       "        [-0.8089,  0.7538, -0.1759, -0.3989, -0.9927,  0.5860,  0.4551,  1.0254],\n",
       "        [-0.2314, -0.7900,  0.3709, -0.9600, -0.1549,  0.9504, -0.5565,  1.0131],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1241, -1.4762,  0.5173, -0.5091, -0.8977,  0.3745, -0.1958, -0.5423]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_norm 不仅改变输出，还改变embedding矩阵本身的值\n",
    "embeddings.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc301f1",
   "metadata": {},
   "source": [
    "# BCELoss()学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3508aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6702, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "0.6702415347099304\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(8, requires_grad=True)\n",
    "target = torch.empty(8).random_(2)\n",
    "output = loss(m(input), target)\n",
    "print(output)\n",
    "print(output.item())    #item()取出对应位置元素的值\n",
    "\n",
    "#only one element tensors can be converted to Python scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15dfac0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1])\n",
      "0.4177626371383667\n",
      "0.4177626371383667\n"
     ]
    }
   ],
   "source": [
    "def validate_loss(output, target, weight=None, pos_weight=None):\n",
    "    # 处理正负样本不均衡问题\n",
    "    if pos_weight is None:\n",
    "        label_size = output.size()[1]\n",
    "        pos_weight = torch.ones(label_size)\n",
    "    # 处理多标签不平衡问题\n",
    "    if weight is None:\n",
    "        label_size = output.size()[1]\n",
    "        weight = torch.ones(label_size)\n",
    "\n",
    "    val = 0\n",
    "    \n",
    "    #两层循环是为了处理多标签二分类问题\n",
    "    \"\"\"\n",
    "    什么是多标签分类？比如说给一篇文章分配话题，它既可以是科技类又可以是教育类，科技和教育就是这篇文章的两个标签。\n",
    "    又比如判断一幅图中包含什么，它可能既包含房子又包含马路。房子和马路就是这幅图对应的两个标签。\n",
    "    将每一种标签，看作是二分类。一个输入样本对应于多个标签，每个标签对应一个二分类（是或不是）。\n",
    "\n",
    "    \"\"\"\n",
    "    for li_x, li_y in zip(output, target):          \n",
    "        #print(li_x)\n",
    "        #print(li_y)\n",
    "        for i, xy in enumerate(zip(li_x, li_y)):\n",
    "            x, y = xy\n",
    "            loss_val = pos_weight[i] * y * math.log(x, math.e) + (1 - y) * math.log(1 - x, math.e)\n",
    "            val += weight[i] * loss_val\n",
    "    return -val / (output.size()[0] * output.size(1))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# 单标签二分类\n",
    "m = nn.Sigmoid()\n",
    "weight = torch.tensor([0.8])\n",
    "loss_fct = nn.BCELoss(reduction=\"mean\", weight=weight)\n",
    "input_src = torch.Tensor([[0.8], [0.9], [0.3]])\n",
    "target = torch.Tensor([[1], [1], [0]])\n",
    "print(input_src.size())\n",
    "print(target.size())\n",
    "output = m(input_src)\n",
    "\n",
    "#print(list(zip(output, target)))\n",
    "loss = loss_fct(output, target)\n",
    "print(loss.item())\n",
    "\n",
    "# 验证计算\n",
    "validate = validate_loss(output, target, weight)\n",
    "print(validate.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e613ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1])\n",
      "0.4177626371383667\n",
      "0.4177626371383667\n"
     ]
    }
   ],
   "source": [
    "# 单标签二分类\n",
    "weight = torch.tensor([0.8])\n",
    "input_src = torch.Tensor([[0.8], [0.9], [0.3]])\n",
    "target = torch.Tensor([[1], [1], [0]])\n",
    "print(input_src.size())\n",
    "print(target.size())\n",
    "output = torch.sigmoid(input_src)\n",
    "loss = F.binary_cross_entropy(output, target, weight=weight, reduction='mean')\n",
    "print(loss.item())\n",
    "\n",
    "# 验证计算\n",
    "validate = validate_loss(output, target, weight)\n",
    "print(validate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f52f6",
   "metadata": {},
   "source": [
    "###  PyTorch  matmul和mm和bmm区别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01a39b",
   "metadata": {},
   "source": [
    "从官方文档可以看出:\n",
    "\n",
    "mm只能进行矩阵乘法,也就是输入的两个tensor维度只能是( n × m ) 和( m × p )\n",
    "\n",
    "bmm是两个三维张量相乘, 两个输入tensor维度是( b × n × m )和( b × m × p ) , 第一维b代表batch size，输出为( b × n × p )\n",
    "\n",
    "matmul可以进行张量乘法, 输入可以是高维."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea34b5b",
   "metadata": {},
   "source": [
    "参考链接： https://blog.csdn.net/leo_95/article/details/89946318?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-89946318-blog-100302375.pc_relevant_3mothn_strategy_and_data_recovery&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-89946318-blog-100302375.pc_relevant_3mothn_strategy_and_data_recovery&utm_relevant_index=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd4ac33",
   "metadata": {},
   "source": [
    "# F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591cf6f8",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/wuliBob/article/details/104119616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abbaf11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T07:18:56.648137Z",
     "start_time": "2023-03-17T07:18:55.623956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9925, -0.1532,  0.1798, -0.2197,  0.1275],\n",
      "        [ 0.2781, -0.7569,  0.9992, -0.1838,  0.8807],\n",
      "        [ 0.5996, -1.7561,  0.2341, -1.8940, -0.6472],\n",
      "        [-1.1586,  0.7348, -1.7754, -0.4019, -1.2543],\n",
      "        [ 1.6600,  2.2298,  0.1292, -0.6996,  1.2672]], requires_grad=True)\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor(1.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9565, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    " # Example of target with class indices\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "#print(target)\n",
    "input = torch.randn(5, 5, requires_grad=True)\n",
    "print(input)\n",
    "target1 = torch.arange(len(input)).long()\n",
    "print(target1)\n",
    "target2 = torch.zeros(input.size())\n",
    "target2.fill_diagonal_(1)  \n",
    "print(target2)\n",
    "loss1 = F.cross_entropy(input, target1)\n",
    "loss2 = -torch.sum(F.log_softmax(input, dim=1)*target2,dim=1).mean()\n",
    "print(loss1)\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1fee90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T07:20:44.502142Z",
     "start_time": "2023-03-17T07:20:44.486142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5063, -0.8038,  1.4741,  0.3065,  0.2809],\n",
      "        [ 0.2667, -0.2912, -1.9044, -0.8381, -1.3603],\n",
      "        [-0.4387, -0.6134,  1.1705, -0.3995, -0.2180],\n",
      "        [ 0.2574, -1.7231, -1.5837, -0.8294,  0.3638],\n",
      "        [-0.0844,  0.4810,  0.3797, -0.1697,  2.2222]], requires_grad=True)\n",
      "tensor([[0.0775, 0.1946, 0.0979, 0.3984, 0.2317],\n",
      "        [0.6843, 0.0433, 0.1948, 0.0341, 0.0435],\n",
      "        [0.1367, 0.1810, 0.2416, 0.2320, 0.2086],\n",
      "        [0.3044, 0.0080, 0.0401, 0.4427, 0.2047],\n",
      "        [0.0807, 0.5314, 0.1309, 0.1487, 0.1083]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0775, 0.1946, 0.0979, 0.3984, 0.2317],\n",
      "        [0.6843, 0.0433, 0.1948, 0.0341, 0.0435],\n",
      "        [0.1367, 0.1810, 0.2416, 0.2320, 0.2086],\n",
      "        [0.3044, 0.0080, 0.0401, 0.4427, 0.2047],\n",
      "        [0.0807, 0.5314, 0.1309, 0.1487, 0.1083]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(1.7678, grad_fn=<DivBackward1>)\n",
      "tensor(1.7678, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class probabilities\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "#print(target)\n",
    "input = torch.randn(5, 5, requires_grad=True)\n",
    "print(input)\n",
    "target1 = torch.randn(5, 5, requires_grad=True).softmax(dim=1)\n",
    "print(target1)\n",
    "target2 = target1  \n",
    "print(target2)\n",
    "loss1 = F.cross_entropy(input, target1)\n",
    "loss2 = -torch.sum(F.log_softmax(input, dim=1)*target2,dim=1).mean()\n",
    "print(loss1)\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9284c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34882078",
   "metadata": {},
   "source": [
    "# device数据流动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a3001f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T05:45:43.172681Z",
     "start_time": "2023-05-16T05:45:43.124313Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a78455a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T05:45:47.200337Z",
     "start_time": "2023-05-16T05:45:45.589706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb49e9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T05:45:53.047103Z",
     "start_time": "2023-05-16T05:45:53.033111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0307d700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T05:52:37.705966Z",
     "start_time": "2023-05-16T05:52:37.688957Z"
    }
   },
   "outputs": [],
   "source": [
    "a=torch.tensor(4)\n",
    "b=torch.tensor(5)\n",
    "c=torch.tensor(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5d96006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T05:52:38.545912Z",
     "start_time": "2023-05-16T05:52:38.538921Z"
    }
   },
   "outputs": [],
   "source": [
    "dict1 ={'a':a,\"b\":b,\"c\":c}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e56a3027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T05:52:39.497133Z",
     "start_time": "2023-05-16T05:52:39.490159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor(4), 'b': tensor(5), 'c': tensor(6)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b5d1e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T06:17:06.185351Z",
     "start_time": "2023-05-16T06:17:06.177357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor(4, device='cuda:0'),\n",
       " 'b': tensor(5, device='cuda:0'),\n",
       " 'c': tensor(6, device='cuda:0')}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict2 = {k: v.to(device) for k, v in dict1.items()}\n",
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf394379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T06:16:18.644275Z",
     "start_time": "2023-05-16T06:16:18.628276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ca0ca43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T06:16:54.697825Z",
     "start_time": "2023-05-16T06:16:54.687876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict2['a'].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fbf1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
