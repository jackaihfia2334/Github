{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXDFpyeik6N3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "ouEBXD1uk6N8",
    "outputId": "8334bd71-1517-40ea-cab0-9db4b7add7bf"
   },
   "outputs": [],
   "source": [
    "workspace_dir = '.'\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount( '/content/drive/' )\n",
    "\n",
    "    workspace_dir = os.path.join( '.' , 'drive', 'My Drive', 'DIN-pytorch')\n",
    "    sys.path.append( workspace_dir)\n",
    "    ! rm -rf data\n",
    "    ! tar zxf \"{workspace_dir}/data.tar.gz\" -C ./\n",
    "    ! tar zxf \"{workspace_dir}/loader.tar.gz\" -C ./\n",
    "    ! ls -al data   \n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMQbWEQBk6N_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import DIN, DIEN, DynamicGRU\n",
    "from DataLoader import MyDataSet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyIw70o-k6OC"
   },
   "outputs": [],
   "source": [
    "#Model hyper parameter\n",
    "MAX_LEN = 100\n",
    "EMBEDDING_DIM = 18\n",
    "# HIDDEN_SIZE_ATTENTION = [80, 40]\n",
    "# HIDDEN_SIZE_FC = [200, 80]\n",
    "# ACTIVATION_LAYER = 'LeakyReLU' # lr = 0.01\n",
    "\n",
    "\n",
    "# Adam\n",
    "LR = 1e-3\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.99\n",
    "\n",
    "# Train\n",
    "BATCH_SIZE = 128\n",
    "EPOCH_TIME = 20\n",
    "TEST_ITER = 1000\n",
    "\n",
    "RANDOM_SEED = 19940808\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NQM5lkgk6OF"
   },
   "outputs": [],
   "source": [
    "train_file = os.path.join( './data', \"local_train_splitByUser\")\n",
    "test_file  = os.path.join( './data', \"local_test_splitByUser\")\n",
    "uid_voc    = os.path.join( './data', \"uid_voc.pkl\")\n",
    "mid_voc    = os.path.join( './data', \"mid_voc.pkl\")\n",
    "cat_voc    = os.path.join( './data', \"cat_voc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnNy6DAqk6OH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_CUDA and torch.cuda.is_available():\n",
    "    print( \"Cuda is avialable\" )\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device( 'cpu')\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qC6I-EKmk6OK"
   },
   "outputs": [],
   "source": [
    "# Stable the random seed\n",
    "def same_seeds(seed = RANDOM_SEED):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  \n",
    "    random.seed(seed) \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Initilize  parameters\n",
    "def weights_init( m):\n",
    "    try:\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find( 'BatchNorm') != -1:\n",
    "            nn.init.normal_( m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_( m.bias.data, 0)\n",
    "        elif classname.find( 'Linear') != -1:\n",
    "            nn.init.normal_( m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find( 'Embedding') != -1:\n",
    "            m.weight.data.uniform_(-1, 1)\n",
    "    except AttributeError:\n",
    "        print( \"AttributeError:\", classname)\n",
    "    \n",
    "\n",
    "\n",
    "def eval_output( scores, target, loss_function = torch.nn.functional.binary_cross_entropy_with_logits):\n",
    "    loss = loss_function( scores.type( dtype) , target.type( dtype))\n",
    "\n",
    "    y_pred = scores.sigmoid().round()\n",
    "    accuracy = ( y_pred == target).type( dtype).mean()\n",
    "\n",
    "    auc = roc_auc_score( target.cpu().detach(), scores.cpu().detach() )\n",
    "    return loss, accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WajPHmvzk6ON"
   },
   "outputs": [],
   "source": [
    "# The dict mapping description(string) to type index(int) \n",
    "# A more graceful api https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder not used in this project\n",
    "\n",
    "user_map = pk.load( open( uid_voc, 'rb')); n_uid = len( user_map)\n",
    "material_map = pk.load( open( mid_voc, 'rb')); n_mid = len( material_map)\n",
    "category_map = pk.load( open( cat_voc, 'rb')); n_cat = len( category_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0dxFeCNk6OP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "same_seeds( RANDOM_SEED)\n",
    "\n",
    "dataset_train = MyDataSet( train_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
    "dataset_test = MyDataSet( test_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader( dataset_train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "loader_test = torch.utils.data.DataLoader( dataset_test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "# with open( 'data/loader.pk', 'rb') as fin:\n",
    "#     loader_train, loader_test = pk.load(fin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([128])\n",
      "torch.Size([128, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([128, 100])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    " for i, data in enumerate(loader_train):\n",
    "        print(len(data))\n",
    "        print(data[0].shape)\n",
    "        print(data[1].shape)\n",
    "        print(data[2][1].shape)\n",
    "        print(data[3].shape)\n",
    "        print(data[4].shape)\n",
    "        print(data[5].shape)\n",
    "        print(data[6].shape)\n",
    "        print(data[7].shape)\n",
    "        print(data[8].shape)\n",
    "        print(data[9].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列1,2,3是dense_feature\n",
    "\n",
    "列0,5,6,7,8是sparse feature\n",
    "\n",
    "列9是label\n",
    "\n",
    "列0-8分别是：user, material_historical, category_historical, mask, sequential_length, \\\n",
    "material, category, material_historical_neg, category_historical_neg = data\n",
    "\n",
    "此外，MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XTRK9jlk6OS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: InputEmbedding\n",
      "[1/20][1000/8486]\tloss:0.69219\tacc:0.50781\tauc:0.53348\tTest Set\tloss:0.66777\tacc:0.57313\tauc:0.61112\n",
      "[1/20][2000/8486]\tloss:0.70538\tacc:0.55469\tauc:0.54682\tTest Set\tloss:0.66535\tacc:0.57387\tauc:0.61516\n",
      "[1/20][3000/8486]\tloss:0.63831\tacc:0.51562\tauc:0.64385\tTest Set\tloss:0.66282\tacc:0.57670\tauc:0.61852\n",
      "[1/20][4000/8486]\tloss:0.63961\tacc:0.59375\tauc:0.65129\tTest Set\tloss:0.66190\tacc:0.57851\tauc:0.62374\n",
      "[1/20][5000/8486]\tloss:0.65196\tacc:0.55469\tauc:0.60440\tTest Set\tloss:0.65866\tacc:0.58061\tauc:0.62940\n",
      "[1/20][6000/8486]\tloss:0.66575\tacc:0.58594\tauc:0.61914\tTest Set\tloss:0.65593\tacc:0.58485\tauc:0.63498\n",
      "[1/20][7000/8486]\tloss:0.61987\tacc:0.67188\tauc:0.71923\tTest Set\tloss:0.65358\tacc:0.58986\tauc:0.64006\n",
      "[1/20][7369/8486]\tloss:0.65480\tacc:0.56250\tauc:0.62858"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m loss, accuracy, auc \u001b[38;5;241m=\u001b[39m eval_output( scores, target)\n\u001b[0;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 27\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m][\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mloss:\u001b[39m\u001b[38;5;132;01m%.5f\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124macc:\u001b[39m\u001b[38;5;132;01m%.5f\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mauc:\u001b[39m\u001b[38;5;132;01m%.5f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m( epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, EPOCH_TIME, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m( loader_train), loss\u001b[38;5;241m.\u001b[39mitem(), accuracy\u001b[38;5;241m.\u001b[39mitem(), auc\u001b[38;5;241m.\u001b[39mitem() ) ,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m TEST_ITER \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torch\\optim\\adam.py:108\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    105\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    107\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 108\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torch\\optim\\_functional.py:85\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m     84\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m---> 85\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmaximum(max_exp_avg_sqs[i], exp_avg_sq, out\u001b[38;5;241m=\u001b[39mmax_exp_avg_sqs[i])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get model and initialize it\n",
    "# model = DIEN(  n_uid, n_mid, n_cat, EMBEDDING_DIM).to( device)\n",
    "model = DIN(  n_uid, n_mid, n_cat, EMBEDDING_DIM ).to( device)\n",
    "model.apply( weights_init)\n",
    "\n",
    "# Set loss function and optimizer\n",
    "optimizer = torch.optim.Adam( model.parameters(), LR, ( BETA1, BETA2))\n",
    "\n",
    "model.train(); iter = 0\n",
    "for epoch in range( EPOCH_TIME):\n",
    "\n",
    "    for i, data in enumerate( loader_train):\n",
    "        iter += 1\n",
    "\n",
    "        # transform data to target device\n",
    "   \n",
    "        data = [ item.to( device) if item != None else None for item in data]\n",
    "        target = data.pop(-1)     \n",
    "        \n",
    "        model.zero_grad()\n",
    "\n",
    "        scores = model( data, neg_sample = False)\n",
    "        \n",
    "        loss, accuracy, auc = eval_output( scores, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step( )\n",
    "        \n",
    "        print( \"\\r[%d/%d][%d/%d]\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( epoch + 1, EPOCH_TIME, i + 1, len( loader_train), loss.item(), accuracy.item(), auc.item() ) ,end='')\n",
    "\n",
    "        if iter % TEST_ITER == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                score_list = []; target_list = []\n",
    "                for data in  loader_test:\n",
    "                    data = [ item.to( device) if item != None else None for item in data]\n",
    "                    \n",
    "                    target = data.pop(-1)\n",
    "\n",
    "                    scores = model( data, neg_sample = False)\n",
    "                    score_list.append( scores)\n",
    "                    target_list.append( target)\n",
    "                scores = torch.cat( score_list, dim = -1)\n",
    "                target = torch.cat( target_list, dim = -1)\n",
    "                loss, accuracy, auc = eval_output( scores, target)\n",
    "                print( \"\\tTest Set\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( loss.item(), accuracy.item(), auc.item() ) )\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 1, 2, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=2\n",
    "[x * 8]+[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1555,  0.2382, -1.1286, -1.4313],\n",
       "        [ 0.5782,  0.5709, -1.8673,  0.0081],\n",
       "        [-0.7404, -0.4467,  1.7358,  1.0103],\n",
       "        [-0.4847, -1.8467,  0.6648, -1.3730],\n",
       "        [ 1.1842, -0.4927, -0.7235, -3.0902],\n",
       "        [ 0.5782,  0.5709, -1.8673,  0.0081],\n",
       "        [-0.7404, -0.4467,  1.7358,  1.0103],\n",
       "        [-0.4847, -1.8467,  0.6648, -1.3730]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = nn.Embedding( 5, 4)\n",
    "x =torch.tensor([0,1,2,3,4,1,2,3])\n",
    "em(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=2\n",
    "D= 8\n",
    "T =10\n",
    "fact = torch.ones(B,T,D)\n",
    "scores = torch.ones(B,1,T)\n",
    "torch.matmul( scores, fact).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
