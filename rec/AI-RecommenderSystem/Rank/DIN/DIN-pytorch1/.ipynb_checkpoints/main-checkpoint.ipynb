{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXDFpyeik6N3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "ouEBXD1uk6N8",
    "outputId": "8334bd71-1517-40ea-cab0-9db4b7add7bf"
   },
   "outputs": [],
   "source": [
    "workspace_dir = '.'\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount( '/content/drive/' )\n",
    "\n",
    "    workspace_dir = os.path.join( '.' , 'drive', 'My Drive', 'DIN-pytorch')\n",
    "    sys.path.append( workspace_dir)\n",
    "    ! rm -rf data\n",
    "    ! tar zxf \"{workspace_dir}/data.tar.gz\" -C ./\n",
    "    ! tar zxf \"{workspace_dir}/loader.tar.gz\" -C ./\n",
    "    ! ls -al data   \n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMQbWEQBk6N_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import DIN, DIEN, DynamicGRU\n",
    "from DataLoader import MyDataSet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyIw70o-k6OC"
   },
   "outputs": [],
   "source": [
    "#Model hyper parameter\n",
    "MAX_LEN = 100\n",
    "EMBEDDING_DIM = 18\n",
    "# HIDDEN_SIZE_ATTENTION = [80, 40]\n",
    "# HIDDEN_SIZE_FC = [200, 80]\n",
    "# ACTIVATION_LAYER = 'LeakyReLU' # lr = 0.01\n",
    "\n",
    "\n",
    "# Adam\n",
    "LR = 1e-3\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.99\n",
    "\n",
    "# Train\n",
    "BATCH_SIZE = 1\n",
    "EPOCH_TIME = 8\n",
    "TEST_ITER = 1000\n",
    "\n",
    "RANDOM_SEED = 19940808\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NQM5lkgk6OF"
   },
   "outputs": [],
   "source": [
    "train_file = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"local_train_splitByUser\")\n",
    "test_file  = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"local_test_splitByUser\")\n",
    "uid_voc    = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"uid_voc.pkl\")\n",
    "mid_voc    = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"mid_voc.pkl\")\n",
    "cat_voc    = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"cat_voc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnNy6DAqk6OH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is avialable\n"
     ]
    }
   ],
   "source": [
    "if USE_CUDA and torch.cuda.is_available():\n",
    "    print( \"Cuda is avialable\" )\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device( 'cpu')\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qC6I-EKmk6OK"
   },
   "outputs": [],
   "source": [
    "# Stable the random seed\n",
    "def same_seeds(seed = RANDOM_SEED):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  \n",
    "    random.seed(seed) \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Initilize  parameters\n",
    "def weights_init( m):\n",
    "    try:\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find( 'BatchNorm') != -1:\n",
    "            nn.init.normal_( m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_( m.bias.data, 0)\n",
    "        elif classname.find( 'Linear') != -1:\n",
    "            nn.init.normal_( m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find( 'Embedding') != -1:\n",
    "            m.weight.data.uniform_(-1, 1)\n",
    "    except AttributeError:\n",
    "        print( \"AttributeError:\", classname)\n",
    "    \n",
    "\n",
    "\n",
    "def eval_output( scores, target, loss_function = torch.nn.functional.binary_cross_entropy_with_logits):\n",
    "    loss = loss_function( scores.type( dtype) , target.type( dtype))\n",
    "\n",
    "    y_pred = scores.sigmoid().round()\n",
    "    accuracy = ( y_pred == target).type( dtype).mean()\n",
    "\n",
    "    auc = roc_auc_score( target.cpu().detach(), scores.cpu().detach() )\n",
    "    return loss, accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WajPHmvzk6ON"
   },
   "outputs": [],
   "source": [
    "# The dict mapping description(string) to type index(int) \n",
    "# A more graceful api https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder not used in this project\n",
    "\n",
    "user_map = pk.load( open( uid_voc, 'rb')); n_uid = len( user_map)\n",
    "material_map = pk.load( open( mid_voc, 'rb')); n_mid = len( material_map)\n",
    "category_map = pk.load( open( cat_voc, 'rb')); n_cat = len( category_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0dxFeCNk6OP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "same_seeds( RANDOM_SEED)\n",
    "\n",
    "dataset_train = MyDataSet( train_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
    "dataset_test = MyDataSet( test_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader( dataset_train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "loader_test = torch.utils.data.DataLoader( dataset_test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "# with open( 'data/loader.pk', 'rb') as fin:\n",
    "#     loader_train, loader_test = pk.load(fin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([352760, 137346, 152333, 339783, 194501, 178354,  21207, 232617, 420058,\n",
      "         84102, 241442, 380336, 321051, 219606, 239608, 205467, 474516, 177376,\n",
      "        386950, 241724, 162134, 203030, 194302, 150100, 212063, 229114, 112254,\n",
      "         24093, 322739, 314737, 176558, 159199, 506760,  18390, 183567, 250885,\n",
      "        423542, 522470, 391819, 298018, 309560, 365366,  44098, 336510,  22591,\n",
      "        173138, 520505, 515811, 246782, 440868, 173192,  85815, 522971,  89828,\n",
      "        307884, 235886, 441291, 336277, 127559, 160352,  10854, 284796, 365439,\n",
      "        537369, 186885, 179460,  71481, 400532,  41263, 479362,  15244, 254966,\n",
      "        211934, 250617, 148578,   5479,  63899, 147994,  32676, 175008, 416940,\n",
      "        369092, 129274, 174058, 442427, 329449, 391995, 467930, 115757, 432033,\n",
      "        118839,   9450,  95833, 316685,   6548,   1350, 357251, 294208,  66163,\n",
      "        526324, 334544, 184436, 463816, 239579, 165912, 330358, 290217, 477659,\n",
      "        473594, 374360, 117121, 449805,  39519, 467738,  78741,  91867, 288189,\n",
      "         85555, 423601, 139896, 168573, 151879,  74770, 408277, 108351, 177064,\n",
      "        349577,  34749]), tensor([[ 41667,   4996,  42136,  ...,      0,      0,      0],\n",
      "        [204866, 278726, 187629,  ...,      0,      0,      0],\n",
      "        [167824, 131526, 140375,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [  7291,    899,   7743,  ...,      0,      0,      0],\n",
      "        [   133,    254,     35,  ...,      0,      0,      0],\n",
      "        [ 87649,  39219, 344458,  ...,      0,      0,      0]]), tensor([[ 1,  1,  1,  ...,  0,  0,  0],\n",
      "        [ 1,  1,  1,  ...,  0,  0,  0],\n",
      "        [ 3, 11, 11,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 1,  1,  1,  ...,  0,  0,  0],\n",
      "        [ 1,  1,  1,  ...,  0,  0,  0],\n",
      "        [ 1,  1,  1,  ...,  0,  0,  0]]), tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]]), tensor([  9,  14,   4,  16,   4,   4,   8,   9,   4,   7,   9,  18,   7,   8,\n",
      "          5,   4,   5,  27,   4,   9,  16,   4,  38,   6,   9,  15,   9,   4,\n",
      "         21,   6,  18,   5,   4, 100,   8,   9,   5,   8,   8,   5,   7,   4,\n",
      "          9,   5,   4,   8,   5,   4,  11,  25,   5,   7,  14,   9,  20,  12,\n",
      "          4, 100,   4,  24,   9,   6,   5,   4,  10,   6,   8,   5,   4,   6,\n",
      "          4,   4,  33,   5,  99,  22,  15,  32,   4,  15,   4,   4,   4,   6,\n",
      "          4,   6,   6,  11,  16,   8,   5,   5,   4,   4,   7,  19,   5,  81,\n",
      "          4,   4,   4,  10,  22,  11,   9,   8,  14,  37,   7,   5,   7,   8,\n",
      "         13,  28,   4,   6,  60,   5,  34,   5,   6,  37,   5,  63,   5,   4,\n",
      "          8,   4]), tensor([293984,  24001, 264299, 123896,   2678,  33454,   2735,  23467,  22922,\n",
      "        291162, 131138,  18126,  65409,   8401,  55044,  41216, 115217,  63391,\n",
      "           812,  20576,   5951, 146181,   6353,  61336,   8205,  75362,  61373,\n",
      "          2065,  74829,  65730, 225205, 178792,  54236,    812,  54990, 184102,\n",
      "        362335,  13591,   3040, 234224,    808, 280276,  40035, 201895,  12571,\n",
      "        129348, 331833,   7577,  12148,   3296,   2867, 190798,  17247, 274553,\n",
      "         14919,    398, 354074, 334952, 342485,  85351,   4990, 193072,    207,\n",
      "        120504, 179321,  74529,  56264,  14533,  92725, 136942, 123390,   5856,\n",
      "        203327,  22524,  37022, 274152, 200134,   1445,  10320,  30698,  12539,\n",
      "        218445, 146385,     29,   1867,   5823,    570, 130242,   2844,    620,\n",
      "           188, 218346,   1645,      6,   2058,  86038,  12133,  26465,  35204,\n",
      "          5871,  67787,  28750,  25411, 284699, 169549, 221776,  55506,  23593,\n",
      "         52785,  82818,   2135, 167599, 194628,    107,  34750, 307582,  10840,\n",
      "        272065, 146401, 366321,  15127, 196020,  13687,   3342, 207124,  19739,\n",
      "         15181,  45001]), tensor([  1,   1, 134,   5,   1,   1,   1,   1,   1,   1,  35,  21,   1,   1,\n",
      "          1,   4,   1,   1,   1,   1,   1,   1,   1,   5,   1, 206,   2,   1,\n",
      "          1,  28,   1,   1,   2,   1,   2,   1,   1,   8,   1,  12,   1,   1,\n",
      "          1,  19,   1,   1,   1,   1,   1,   1,  14,   1,   1,   2,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   6,   1,   1,   1,   1,\n",
      "         96,  85,   1,   1,   1,   1,   1,   1,   1,   4,   1, 961,   1,   1,\n",
      "          1,   1,   1,   1,   1,   2,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   2,   1,   1, 678,   2,   2,   2,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1, 176,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   2]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0])]\n",
      "torch.Size([128])\n",
      "torch.Size([128, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([128, 100])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    " for i, data in enumerate(loader_train):\n",
    "        print(data)\n",
    "        print(data[0].shape)\n",
    "        print(data[1].shape)\n",
    "        print(data[2][1].shape)\n",
    "        print(data[3].shape)\n",
    "        print(data[4].shape)\n",
    "        print(data[5].shape)\n",
    "        print(data[6].shape)\n",
    "        print(data[7].shape)\n",
    "        print(data[8].shape)\n",
    "        print(data[9].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列1,2,3是历史特征（序列）\n",
    "\n",
    "列0,5,6,7,8是 单一特征（非序列）\n",
    "\n",
    "列9是label\n",
    "\n",
    "列0-8分别是：user, material_historical, category_historical, mask, sequential_length, \\\n",
    "material, category, material_historical_neg, category_historical_neg = data\n",
    "\n",
    "此外，MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XTRK9jlk6OS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: InputEmbedding\n",
      "[1/8][1000/8486]\tloss:0.63218\tacc:0.71875\tauc:0.72562\tTest Set\tloss:0.66733\tacc:0.57270\tauc:0.61044\n",
      "[1/8][2000/8486]\tloss:0.68149\tacc:0.57812\tauc:0.58908\tTest Set\tloss:0.66584\tacc:0.57454\tauc:0.61439\n",
      "[1/8][3000/8486]\tloss:0.66451\tacc:0.60938\tauc:0.63074\tTest Set\tloss:0.66235\tacc:0.57846\tauc:0.61965\n",
      "[1/8][4000/8486]\tloss:0.68344\tacc:0.50781\tauc:0.55360\tTest Set\tloss:0.65979\tacc:0.57924\tauc:0.62521\n",
      "[1/8][5000/8486]\tloss:0.70015\tacc:0.57031\tauc:0.58033\tTest Set\tloss:0.65800\tacc:0.58242\tauc:0.63014\n",
      "[1/8][6000/8486]\tloss:0.65650\tacc:0.57031\tauc:0.63046\tTest Set\tloss:0.65538\tacc:0.58453\tauc:0.63417\n",
      "[1/8][7000/8486]\tloss:0.62890\tacc:0.58594\tauc:0.66078\tTest Set\tloss:0.65316\tacc:0.58861\tauc:0.63919\n",
      "[1/8][8000/8486]\tloss:0.62872\tacc:0.61719\tauc:0.67627\tTest Set\tloss:0.65144\tacc:0.59232\tauc:0.64432\n",
      "[2/8][514/8486]\tloss:0.65489\tacc:0.56250\tauc:0.618808\tTest Set\tloss:0.65015\tacc:0.59415\tauc:0.64696\n",
      "[2/8][1514/8486]\tloss:0.60853\tacc:0.64062\tauc:0.71299\tTest Set\tloss:0.64951\tacc:0.59657\tauc:0.65039\n",
      "[2/8][2514/8486]\tloss:0.63592\tacc:0.56250\tauc:0.65665\tTest Set\tloss:0.64725\tacc:0.59883\tauc:0.65278\n",
      "[2/8][3514/8486]\tloss:0.70064\tacc:0.52344\tauc:0.58516\tTest Set\tloss:0.64662\tacc:0.60150\tauc:0.65614\n",
      "[2/8][4514/8486]\tloss:0.63041\tacc:0.59375\tauc:0.67660\tTest Set\tloss:0.64163\tacc:0.60644\tauc:0.66347\n",
      "[2/8][5514/8486]\tloss:0.60541\tacc:0.60938\tauc:0.71270\tTest Set\tloss:0.63956\tacc:0.60963\tauc:0.66731\n",
      "[2/8][6514/8486]\tloss:0.61284\tacc:0.61719\tauc:0.70508\tTest Set\tloss:0.63815\tacc:0.61216\tauc:0.67073\n",
      "[2/8][7514/8486]\tloss:0.58115\tacc:0.72656\tauc:0.78055\tTest Set\tloss:0.63568\tacc:0.61590\tauc:0.67536\n",
      "[3/8][28/8486]\tloss:0.60922\tacc:0.64062\tauc:0.7247062\tTest Set\tloss:0.63408\tacc:0.61951\tauc:0.67845\n",
      "[3/8][1028/8486]\tloss:0.60809\tacc:0.61719\tauc:0.70614\tTest Set\tloss:0.63443\tacc:0.62074\tauc:0.68142\n",
      "[3/8][2028/8486]\tloss:0.54037\tacc:0.70312\tauc:0.80855\tTest Set\tloss:0.63099\tacc:0.62378\tauc:0.68605\n",
      "[3/8][3028/8486]\tloss:0.59723\tacc:0.67188\tauc:0.73926\tTest Set\tloss:0.63027\tacc:0.62568\tauc:0.68858\n",
      "[3/8][4028/8486]\tloss:0.57562\tacc:0.68750\tauc:0.77077\tTest Set\tloss:0.62606\tacc:0.63087\tauc:0.69432\n",
      "[3/8][5028/8486]\tloss:0.62192\tacc:0.65625\tauc:0.72674\tTest Set\tloss:0.62276\tacc:0.63341\tauc:0.69830\n",
      "[3/8][6028/8486]\tloss:0.55486\tacc:0.71094\tauc:0.78687\tTest Set\tloss:0.62144\tacc:0.63502\tauc:0.70071\n",
      "[3/8][6101/8486]\tloss:0.53987\tacc:0.69531\tauc:0.79130"
     ]
    }
   ],
   "source": [
    "# Get model and initialize it\n",
    "# model = DIEN(  n_uid, n_mid, n_cat, EMBEDDING_DIM).to( device)\n",
    "model = DIN(  n_uid, n_mid, n_cat, EMBEDDING_DIM ).to( device)\n",
    "model.apply( weights_init)\n",
    "\n",
    "# Set loss function and optimizer\n",
    "optimizer = torch.optim.Adam( model.parameters(), LR, ( BETA1, BETA2))\n",
    "\n",
    "model.train(); iter = 0\n",
    "for epoch in range( EPOCH_TIME):\n",
    "\n",
    "    for i, data in enumerate( loader_train):\n",
    "        iter += 1\n",
    "\n",
    "        # transform data to target device\n",
    "   \n",
    "        data = [ item.to( device) if item != None else None for item in data]\n",
    "        target = data.pop(-1)     \n",
    "        \n",
    "        model.zero_grad()\n",
    "\n",
    "        scores = model( data, neg_sample = False)\n",
    "        \n",
    "        loss, accuracy, auc = eval_output( scores, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step( )\n",
    "        \n",
    "        print( \"\\r[%d/%d][%d/%d]\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( epoch + 1, EPOCH_TIME, i + 1, len( loader_train), loss.item(), accuracy.item(), auc.item() ) ,end='')\n",
    "\n",
    "        if iter % TEST_ITER == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                score_list = []; target_list = []\n",
    "                for data in  loader_test:\n",
    "                    data = [ item.to( device) if item != None else None for item in data]\n",
    "                    \n",
    "                    target = data.pop(-1)\n",
    "\n",
    "                    scores = model( data, neg_sample = False)\n",
    "                    score_list.append( scores)\n",
    "                    target_list.append( target)\n",
    "                scores = torch.cat( score_list, dim = -1)\n",
    "                target = torch.cat( target_list, dim = -1)\n",
    "                loss, accuracy, auc = eval_output( scores, target)\n",
    "                print( \"\\tTest Set\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( loss.item(), accuracy.item(), auc.item() ) )\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 1, 2, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=2\n",
    "[x * 8]+[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1555,  0.2382, -1.1286, -1.4313],\n",
       "        [ 0.5782,  0.5709, -1.8673,  0.0081],\n",
       "        [-0.7404, -0.4467,  1.7358,  1.0103],\n",
       "        [-0.4847, -1.8467,  0.6648, -1.3730],\n",
       "        [ 1.1842, -0.4927, -0.7235, -3.0902],\n",
       "        [ 0.5782,  0.5709, -1.8673,  0.0081],\n",
       "        [-0.7404, -0.4467,  1.7358,  1.0103],\n",
       "        [-0.4847, -1.8467,  0.6648, -1.3730]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = nn.Embedding( 5, 4)\n",
    "x =torch.tensor([0,1,2,3,4,1,2,3])\n",
    "em(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=2\n",
    "D= 8\n",
    "T =10\n",
    "fact = torch.ones(B,T,D)\n",
    "scores = torch.ones(B,1,T)\n",
    "torch.matmul( scores, fact).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
