{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXDFpyeik6N3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "ouEBXD1uk6N8",
    "outputId": "8334bd71-1517-40ea-cab0-9db4b7add7bf"
   },
   "outputs": [],
   "source": [
    "workspace_dir = '.'\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount( '/content/drive/' )\n",
    "\n",
    "    workspace_dir = os.path.join( '.' , 'drive', 'My Drive', 'DIN-pytorch')\n",
    "    sys.path.append( workspace_dir)\n",
    "    ! rm -rf data\n",
    "    ! tar zxf \"{workspace_dir}/data.tar.gz\" -C ./\n",
    "    ! tar zxf \"{workspace_dir}/loader.tar.gz\" -C ./\n",
    "    ! ls -al data   \n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMQbWEQBk6N_",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from model import DIN, DIEN, DynamicGRU\n",
    "from DataLoader import MyDataSet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyIw70o-k6OC"
   },
   "outputs": [],
   "source": [
    "#Model hyper parameter\n",
    "MAX_LEN = 100\n",
    "EMBEDDING_DIM = 18\n",
    "# HIDDEN_SIZE_ATTENTION = [80, 40]\n",
    "# HIDDEN_SIZE_FC = [200, 80]\n",
    "# ACTIVATION_LAYER = 'LeakyReLU' # lr = 0.01\n",
    "\n",
    "\n",
    "# Adam\n",
    "LR = 1e-3\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.99\n",
    "\n",
    "# Train\n",
    "BATCH_SIZE = 1\n",
    "EPOCH_TIME = 8\n",
    "TEST_ITER = 1000\n",
    "\n",
    "RANDOM_SEED = 19940808\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NQM5lkgk6OF"
   },
   "outputs": [],
   "source": [
    "train_file = os.path.join( 'D:/myf/data/rec_DIN_pytorch1/data', \"local_train_splitByUser\")\n",
    "test_file  = os.path.join( 'D:/myf/data/rec_DIN_pytorch1/data', \"local_test_splitByUser\")\n",
    "uid_voc    = os.path.join( 'D:/myf/data/rec_DIN_pytorch1/data', \"uid_voc.pkl\")\n",
    "mid_voc    = os.path.join( 'D:/myf/data/rec_DIN_pytorch1/data', \"mid_voc.pkl\")\n",
    "cat_voc    = os.path.join( 'D:/myf/data/rec_DIN_pytorch1/data', \"cat_voc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnNy6DAqk6OH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_CUDA and torch.cuda.is_available():\n",
    "    print( \"Cuda is avialable\" )\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device( 'cpu')\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qC6I-EKmk6OK"
   },
   "outputs": [],
   "source": [
    "# Stable the random seed\n",
    "def same_seeds(seed = RANDOM_SEED):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  \n",
    "    random.seed(seed) \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Initilize  parameters\n",
    "def weights_init( m):\n",
    "    try:\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find( 'BatchNorm') != -1:\n",
    "            nn.init.normal_( m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_( m.bias.data, 0)\n",
    "        elif classname.find( 'Linear') != -1:\n",
    "            nn.init.normal_( m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find( 'Embedding') != -1:\n",
    "            m.weight.data.uniform_(-1, 1)\n",
    "    except AttributeError:\n",
    "        print( \"AttributeError:\", classname)\n",
    "    \n",
    "\n",
    "\n",
    "def eval_output( scores, target, loss_function = torch.nn.functional.binary_cross_entropy_with_logits):\n",
    "    loss = loss_function( scores.type( dtype) , target.type( dtype))\n",
    "\n",
    "    y_pred = scores.sigmoid().round()\n",
    "    accuracy = ( y_pred == target).type( dtype).mean()\n",
    "\n",
    "    auc = roc_auc_score( target.cpu().detach(), scores.cpu().detach() )\n",
    "    return loss, accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WajPHmvzk6ON"
   },
   "outputs": [],
   "source": [
    "# The dict mapping description(string) to type index(int) \n",
    "# A more graceful api https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder not used in this project\n",
    "\n",
    "user_map = pk.load( open( uid_voc, 'rb')); n_uid = len( user_map)\n",
    "material_map = pk.load( open( mid_voc, 'rb')); n_mid = len( material_map)\n",
    "category_map = pk.load( open( cat_voc, 'rb')); n_cat = len( category_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0dxFeCNk6OP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "same_seeds( RANDOM_SEED)\n",
    "\n",
    "dataset_train = MyDataSet( train_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
    "dataset_test = MyDataSet( test_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader( dataset_train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "loader_test = torch.utils.data.DataLoader( dataset_test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "# with open( 'data/loader.pk', 'rb') as fin:\n",
    "#     loader_train, loader_test = pk.load(fin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([352760]), tensor([[41667,  4996, 42136, 73494, 68549, 10342, 29868,  5004, 24174,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([9]), tensor([293984]), tensor([1]), tensor([0]), tensor([0]), tensor([0])]\n",
      "torch.Size([1])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    " for i, data in enumerate(loader_train):\n",
    "        print(data)\n",
    "        print(data[0].shape)\n",
    "        print(data[1].shape)\n",
    "        print(data[2].shape)\n",
    "        print(data[3].shape)\n",
    "        print(data[4].shape)\n",
    "        print(data[5].shape)\n",
    "        print(data[6].shape)\n",
    "        print(data[7].shape)\n",
    "        print(data[8].shape)\n",
    "        print(data[9].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列1,2,3是历史特征（序列）\n",
    "\n",
    "列0,5,6,7,8是 单一特征（非序列）\n",
    "\n",
    "列9是label\n",
    "\n",
    "列0-8分别是：user, material_historical, category_historical, mask, sequential_length, \\\n",
    "material, category, material_historical_neg, category_historical_neg = data\n",
    "\n",
    "此外，MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XTRK9jlk6OS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: InputEmbedding\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\MyGit\\Github\\rec\\AI-RecommenderSystem\\Rank\\DIN\\DIN-pytorch1\\main.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MyGit/Github/rec/AI-RecommenderSystem/Rank/DIN/DIN-pytorch1/main.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mpop(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)     \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MyGit/Github/rec/AI-RecommenderSystem/Rank/DIN/DIN-pytorch1/main.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MyGit/Github/rec/AI-RecommenderSystem/Rank/DIN/DIN-pytorch1/main.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m scores \u001b[39m=\u001b[39m model( data, neg_sample \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MyGit/Github/rec/AI-RecommenderSystem/Rank/DIN/DIN-pytorch1/main.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss, accuracy, auc \u001b[39m=\u001b[39m eval_output( scores, target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MyGit/Github/rec/AI-RecommenderSystem/Rank/DIN/DIN-pytorch1/main.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\MyGit\\Github\\rec\\AI-RecommenderSystem\\Rank\\DIN\\DIN-pytorch1\\model.py:34\u001b[0m, in \u001b[0;36mDIN.forward\u001b[1;34m(self, data, neg_sample)\u001b[0m\n\u001b[0;32m     27\u001b[0m user, material_historical, category_historical, mask, sequential_length , material, category, \\\n\u001b[0;32m     28\u001b[0m     material_historical_neg, category_historical_neg \u001b[39m=\u001b[39m data\n\u001b[0;32m     30\u001b[0m user_embedding, material_historical_embedding, category_historical_embedding, \\\n\u001b[0;32m     31\u001b[0m     material_embedding, category_embedding, material_historical_neg_embedding, category_historical_neg_embedding \u001b[39m=\u001b[39m \\\n\u001b[0;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_layer(  user, material, category, material_historical, category_historical, material_historical_neg, category_historical_neg, neg_sample)\n\u001b[1;32m---> 34\u001b[0m item_embedding \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat( [ material_embedding, category_embedding], dim \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     35\u001b[0m item_historical_embedding \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat( [ material_historical_embedding, category_historical_embedding], dim \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m )\n\u001b[0;32m     37\u001b[0m item_historical_embedding_sum \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul( mask\u001b[39m.\u001b[39munsqueeze( dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m), item_historical_embedding)\u001b[39m.\u001b[39msqueeze() \u001b[39m/\u001b[39m sequential_length\u001b[39m.\u001b[39mtype( mask\u001b[39m.\u001b[39mtype() )\u001b[39m.\u001b[39munsqueeze( dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "# Get model and initialize it\n",
    "# model = DIEN(  n_uid, n_mid, n_cat, EMBEDDING_DIM).to( device)\n",
    "model = DIN(  n_uid, n_mid, n_cat, EMBEDDING_DIM ).to( device)\n",
    "model.apply( weights_init)\n",
    "\n",
    "# Set loss function and optimizer\n",
    "optimizer = torch.optim.Adam( model.parameters(), LR, ( BETA1, BETA2))\n",
    "\n",
    "model.train(); iter = 0\n",
    "for epoch in range( EPOCH_TIME):\n",
    "\n",
    "    for i, data in enumerate( loader_train):\n",
    "        iter += 1\n",
    "\n",
    "        # transform data to target device\n",
    "   \n",
    "        data = [ item.to( device) if item != None else None for item in data]\n",
    "        target = data.pop(-1)     \n",
    "        \n",
    "        model.zero_grad()\n",
    "\n",
    "        scores = model( data, neg_sample = False)\n",
    "        \n",
    "        loss, accuracy, auc = eval_output( scores, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step( )\n",
    "        \n",
    "        print( \"\\r[%d/%d][%d/%d]\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( epoch + 1, EPOCH_TIME, i + 1, len( loader_train), loss.item(), accuracy.item(), auc.item() ) ,end='')\n",
    "\n",
    "        if iter % TEST_ITER == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                score_list = []; target_list = []\n",
    "                for data in  loader_test:\n",
    "                    data = [ item.to( device) if item != None else None for item in data]\n",
    "                    \n",
    "                    target = data.pop(-1)\n",
    "\n",
    "                    scores = model( data, neg_sample = False)\n",
    "                    score_list.append( scores)\n",
    "                    target_list.append( target)\n",
    "                scores = torch.cat( score_list, dim = -1)\n",
    "                target = torch.cat( target_list, dim = -1)\n",
    "                loss, accuracy, auc = eval_output( scores, target)\n",
    "                print( \"\\tTest Set\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( loss.item(), accuracy.item(), auc.item() ) )\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 1, 2, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=2\n",
    "[x * 8]+[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1555,  0.2382, -1.1286, -1.4313],\n",
       "        [ 0.5782,  0.5709, -1.8673,  0.0081],\n",
       "        [-0.7404, -0.4467,  1.7358,  1.0103],\n",
       "        [-0.4847, -1.8467,  0.6648, -1.3730],\n",
       "        [ 1.1842, -0.4927, -0.7235, -3.0902],\n",
       "        [ 0.5782,  0.5709, -1.8673,  0.0081],\n",
       "        [-0.7404, -0.4467,  1.7358,  1.0103],\n",
       "        [-0.4847, -1.8467,  0.6648, -1.3730]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = nn.Embedding( 5, 4)\n",
    "x =torch.tensor([0,1,2,3,4,1,2,3])\n",
    "em(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=2\n",
    "D= 8\n",
    "T =10\n",
    "fact = torch.ones(B,T,D)\n",
    "scores = torch.ones(B,1,T)\n",
    "torch.matmul( scores, fact).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1,2,3])\n",
    "y=torch.tensor([1,2,3])\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
