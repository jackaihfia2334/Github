{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXDFpyeik6N3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "ouEBXD1uk6N8",
    "outputId": "8334bd71-1517-40ea-cab0-9db4b7add7bf"
   },
   "outputs": [],
   "source": [
    "workspace_dir = '.'\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount( '/content/drive/' )\n",
    "\n",
    "    workspace_dir = os.path.join( '.' , 'drive', 'My Drive', 'DIN-pytorch')\n",
    "    sys.path.append( workspace_dir)\n",
    "    ! rm -rf data\n",
    "    ! tar zxf \"{workspace_dir}/data.tar.gz\" -C ./\n",
    "    ! tar zxf \"{workspace_dir}/loader.tar.gz\" -C ./\n",
    "    ! ls -al data   \n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMQbWEQBk6N_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import DIN, DIEN, DynamicGRU\n",
    "from DataLoader import MyDataSet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyIw70o-k6OC"
   },
   "outputs": [],
   "source": [
    "#Model hyper parameter\n",
    "MAX_LEN = 100\n",
    "EMBEDDING_DIM = 18\n",
    "# HIDDEN_SIZE_ATTENTION = [80, 40]\n",
    "# HIDDEN_SIZE_FC = [200, 80]\n",
    "# ACTIVATION_LAYER = 'LeakyReLU' # lr = 0.01\n",
    "\n",
    "\n",
    "# Adam\n",
    "LR = 1e-3\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.99\n",
    "\n",
    "# Train\n",
    "BATCH_SIZE = 1\n",
    "EPOCH_TIME = 8\n",
    "TEST_ITER = 1000\n",
    "\n",
    "RANDOM_SEED = 19940808\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NQM5lkgk6OF"
   },
   "outputs": [],
   "source": [
    "train_file = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"local_train_splitByUser\")\n",
    "test_file  = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"local_test_splitByUser\")\n",
    "uid_voc    = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"uid_voc.pkl\")\n",
    "mid_voc    = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"mid_voc.pkl\")\n",
    "cat_voc    = os.path.join( 'C:/Users/myf/MyGit/data/rec_DIN_pytorch1/data', \"cat_voc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnNy6DAqk6OH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is avialable\n"
     ]
    }
   ],
   "source": [
    "if USE_CUDA and torch.cuda.is_available():\n",
    "    print( \"Cuda is avialable\" )\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device( 'cpu')\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qC6I-EKmk6OK"
   },
   "outputs": [],
   "source": [
    "# Stable the random seed\n",
    "def same_seeds(seed = RANDOM_SEED):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  \n",
    "    random.seed(seed) \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Initilize  parameters\n",
    "def weights_init( m):\n",
    "    try:\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find( 'BatchNorm') != -1:\n",
    "            nn.init.normal_( m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_( m.bias.data, 0)\n",
    "        elif classname.find( 'Linear') != -1:\n",
    "            nn.init.normal_( m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find( 'Embedding') != -1:\n",
    "            m.weight.data.uniform_(-1, 1)\n",
    "    except AttributeError:\n",
    "        print( \"AttributeError:\", classname)\n",
    "    \n",
    "\n",
    "\n",
    "def eval_output( scores, target, loss_function = torch.nn.functional.binary_cross_entropy_with_logits):\n",
    "    loss = loss_function( scores.type( dtype) , target.type( dtype))\n",
    "\n",
    "    y_pred = scores.sigmoid().round()\n",
    "    accuracy = ( y_pred == target).type( dtype).mean()\n",
    "\n",
    "    auc = roc_auc_score( target.cpu().detach(), scores.cpu().detach() )\n",
    "    return loss, accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WajPHmvzk6ON"
   },
   "outputs": [],
   "source": [
    "# The dict mapping description(string) to type index(int) \n",
    "# A more graceful api https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder not used in this project\n",
    "\n",
    "user_map = pk.load( open( uid_voc, 'rb')); n_uid = len( user_map)\n",
    "material_map = pk.load( open( mid_voc, 'rb')); n_mid = len( material_map)\n",
    "category_map = pk.load( open( cat_voc, 'rb')); n_cat = len( category_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0dxFeCNk6OP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "same_seeds( RANDOM_SEED)\n",
    "\n",
    "dataset_train = MyDataSet( train_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
    "dataset_test = MyDataSet( test_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader( dataset_train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "loader_test = torch.utils.data.DataLoader( dataset_test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "# with open( 'data/loader.pk', 'rb') as fin:\n",
    "#     loader_train, loader_test = pk.load(fin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([352760]), tensor([[41667,  4996, 42136, 73494, 68549, 10342, 29868,  5004, 24174,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([9]), tensor([293984]), tensor([1]), tensor([0]), tensor([0]), tensor([0])]\n",
      "torch.Size([1])\n",
      "torch.Size([1, 100])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4551b45541da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    " for i, data in enumerate(loader_train):\n",
    "        print(data)\n",
    "        print(data[0].shape)\n",
    "        print(data[1].shape)\n",
    "        print(data[2][1].shape)\n",
    "        print(data[3].shape)\n",
    "        print(data[4].shape)\n",
    "        print(data[5].shape)\n",
    "        print(data[6].shape)\n",
    "        print(data[7].shape)\n",
    "        print(data[8].shape)\n",
    "        print(data[9].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列1,2,3是历史特征（序列）\n",
    "\n",
    "列0,5,6,7,8是 单一特征（非序列）\n",
    "\n",
    "列9是label\n",
    "\n",
    "列0-8分别是：user, material_historical, category_historical, mask, sequential_length, \\\n",
    "material, category, material_historical_neg, category_historical_neg = data\n",
    "\n",
    "此外，MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XTRK9jlk6OS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: InputEmbedding\n",
      "[1/8][1000/8486]\tloss:0.63218\tacc:0.71875\tauc:0.72562\tTest Set\tloss:0.66733\tacc:0.57270\tauc:0.61044\n",
      "[1/8][2000/8486]\tloss:0.68149\tacc:0.57812\tauc:0.58908\tTest Set\tloss:0.66584\tacc:0.57454\tauc:0.61439\n",
      "[1/8][3000/8486]\tloss:0.66451\tacc:0.60938\tauc:0.63074\tTest Set\tloss:0.66235\tacc:0.57846\tauc:0.61965\n",
      "[1/8][4000/8486]\tloss:0.68344\tacc:0.50781\tauc:0.55360\tTest Set\tloss:0.65979\tacc:0.57924\tauc:0.62521\n",
      "[1/8][5000/8486]\tloss:0.70015\tacc:0.57031\tauc:0.58033\tTest Set\tloss:0.65800\tacc:0.58242\tauc:0.63014\n",
      "[1/8][6000/8486]\tloss:0.65650\tacc:0.57031\tauc:0.63046\tTest Set\tloss:0.65538\tacc:0.58453\tauc:0.63417\n",
      "[1/8][7000/8486]\tloss:0.62890\tacc:0.58594\tauc:0.66078\tTest Set\tloss:0.65316\tacc:0.58861\tauc:0.63919\n",
      "[1/8][8000/8486]\tloss:0.62872\tacc:0.61719\tauc:0.67627\tTest Set\tloss:0.65144\tacc:0.59232\tauc:0.64432\n",
      "[2/8][514/8486]\tloss:0.65489\tacc:0.56250\tauc:0.618808\tTest Set\tloss:0.65015\tacc:0.59415\tauc:0.64696\n",
      "[2/8][1514/8486]\tloss:0.60853\tacc:0.64062\tauc:0.71299\tTest Set\tloss:0.64951\tacc:0.59657\tauc:0.65039\n",
      "[2/8][2514/8486]\tloss:0.63592\tacc:0.56250\tauc:0.65665\tTest Set\tloss:0.64725\tacc:0.59883\tauc:0.65278\n",
      "[2/8][3514/8486]\tloss:0.70064\tacc:0.52344\tauc:0.58516\tTest Set\tloss:0.64662\tacc:0.60150\tauc:0.65614\n",
      "[2/8][4514/8486]\tloss:0.63041\tacc:0.59375\tauc:0.67660\tTest Set\tloss:0.64163\tacc:0.60644\tauc:0.66347\n",
      "[2/8][5514/8486]\tloss:0.60541\tacc:0.60938\tauc:0.71270\tTest Set\tloss:0.63956\tacc:0.60963\tauc:0.66731\n",
      "[2/8][6514/8486]\tloss:0.61284\tacc:0.61719\tauc:0.70508\tTest Set\tloss:0.63815\tacc:0.61216\tauc:0.67073\n",
      "[2/8][7514/8486]\tloss:0.58115\tacc:0.72656\tauc:0.78055\tTest Set\tloss:0.63568\tacc:0.61590\tauc:0.67536\n",
      "[3/8][28/8486]\tloss:0.60922\tacc:0.64062\tauc:0.7247062\tTest Set\tloss:0.63408\tacc:0.61951\tauc:0.67845\n",
      "[3/8][1028/8486]\tloss:0.60809\tacc:0.61719\tauc:0.70614\tTest Set\tloss:0.63443\tacc:0.62074\tauc:0.68142\n",
      "[3/8][2028/8486]\tloss:0.54037\tacc:0.70312\tauc:0.80855\tTest Set\tloss:0.63099\tacc:0.62378\tauc:0.68605\n",
      "[3/8][3028/8486]\tloss:0.59723\tacc:0.67188\tauc:0.73926\tTest Set\tloss:0.63027\tacc:0.62568\tauc:0.68858\n",
      "[3/8][4028/8486]\tloss:0.57562\tacc:0.68750\tauc:0.77077\tTest Set\tloss:0.62606\tacc:0.63087\tauc:0.69432\n",
      "[3/8][5028/8486]\tloss:0.62192\tacc:0.65625\tauc:0.72674\tTest Set\tloss:0.62276\tacc:0.63341\tauc:0.69830\n",
      "[3/8][6028/8486]\tloss:0.55486\tacc:0.71094\tauc:0.78687\tTest Set\tloss:0.62144\tacc:0.63502\tauc:0.70071\n",
      "[3/8][6101/8486]\tloss:0.53987\tacc:0.69531\tauc:0.79130"
     ]
    }
   ],
   "source": [
    "# Get model and initialize it\n",
    "# model = DIEN(  n_uid, n_mid, n_cat, EMBEDDING_DIM).to( device)\n",
    "model = DIN(  n_uid, n_mid, n_cat, EMBEDDING_DIM ).to( device)\n",
    "model.apply( weights_init)\n",
    "\n",
    "# Set loss function and optimizer\n",
    "optimizer = torch.optim.Adam( model.parameters(), LR, ( BETA1, BETA2))\n",
    "\n",
    "model.train(); iter = 0\n",
    "for epoch in range( EPOCH_TIME):\n",
    "\n",
    "    for i, data in enumerate( loader_train):\n",
    "        iter += 1\n",
    "\n",
    "        # transform data to target device\n",
    "   \n",
    "        data = [ item.to( device) if item != None else None for item in data]\n",
    "        target = data.pop(-1)     \n",
    "        \n",
    "        model.zero_grad()\n",
    "\n",
    "        scores = model( data, neg_sample = False)\n",
    "        \n",
    "        loss, accuracy, auc = eval_output( scores, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step( )\n",
    "        \n",
    "        print( \"\\r[%d/%d][%d/%d]\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( epoch + 1, EPOCH_TIME, i + 1, len( loader_train), loss.item(), accuracy.item(), auc.item() ) ,end='')\n",
    "\n",
    "        if iter % TEST_ITER == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                score_list = []; target_list = []\n",
    "                for data in  loader_test:\n",
    "                    data = [ item.to( device) if item != None else None for item in data]\n",
    "                    \n",
    "                    target = data.pop(-1)\n",
    "\n",
    "                    scores = model( data, neg_sample = False)\n",
    "                    score_list.append( scores)\n",
    "                    target_list.append( target)\n",
    "                scores = torch.cat( score_list, dim = -1)\n",
    "                target = torch.cat( target_list, dim = -1)\n",
    "                loss, accuracy, auc = eval_output( scores, target)\n",
    "                print( \"\\tTest Set\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( loss.item(), accuracy.item(), auc.item() ) )\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 1, 2, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=2\n",
    "[x * 8]+[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1555,  0.2382, -1.1286, -1.4313],\n",
       "        [ 0.5782,  0.5709, -1.8673,  0.0081],\n",
       "        [-0.7404, -0.4467,  1.7358,  1.0103],\n",
       "        [-0.4847, -1.8467,  0.6648, -1.3730],\n",
       "        [ 1.1842, -0.4927, -0.7235, -3.0902],\n",
       "        [ 0.5782,  0.5709, -1.8673,  0.0081],\n",
       "        [-0.7404, -0.4467,  1.7358,  1.0103],\n",
       "        [-0.4847, -1.8467,  0.6648, -1.3730]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = nn.Embedding( 5, 4)\n",
    "x =torch.tensor([0,1,2,3,4,1,2,3])\n",
    "em(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=2\n",
    "D= 8\n",
    "T =10\n",
    "fact = torch.ones(B,T,D)\n",
    "scores = torch.ones(B,1,T)\n",
    "torch.matmul( scores, fact).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1,2,3])\n",
    "y=torch.tensor([1,2,3])\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
