{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "这里使用掉包的方式和亲自造轮子的方式进行kaggle上的criteo数据集的实战， 关于这个数据集的下载和介绍， 可以见GBDT+LR的那一节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T01:06:53.365695Z",
     "start_time": "2020-09-26T01:06:53.361750Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from pyfm import pylibfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据导入与简单处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T01:06:54.823126Z",
     "start_time": "2020-09-26T01:06:54.778205Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据读取\n",
    "path = 'criteo/'\n",
    "df_train = pd.read_csv(path + 'train.csv')\n",
    "df_test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "# 简单的数据预处理\n",
    "# 去掉id列， 把测试集和训练集合并， 填充缺失值\n",
    "df_train.drop(['Id'], axis=1, inplace=True)\n",
    "df_test.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "df_test['Label'] = -1\n",
    "\n",
    "data = pd.concat([df_train, df_test])\n",
    "data.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T14:14:54.712358Z",
     "start_time": "2020-09-25T14:14:54.671467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>c393dc22</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>57c90cd9</td>\n",
       "      <td>-1</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>4d19a3eb</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>456c12a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>92555263</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>-1</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a0136dd2</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f37f3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>c3abeb21</td>\n",
       "      <td>-1</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>642f2610</td>\n",
       "      <td>1d1eb838</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>1640d50b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>d16737e3</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>edc49a33</td>\n",
       "      <td>-1</td>\n",
       "      <td>93bad2c0</td>\n",
       "      <td>3fdb382b</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>80dd0a5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>5162930e</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12965bb8</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>71292dbb</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4622.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>a78bd508</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>c2a93b37</td>\n",
       "      <td>-1</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>2fede552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>a1d0cc4f</td>\n",
       "      <td>c68db44a</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>3b1ae854</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>57e2c6c9</td>\n",
       "      <td>1575c75f</td>\n",
       "      <td>7132fed8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36144.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>7b49e3d2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>dfcfc3fa</td>\n",
       "      <td>-1</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>aee52b6f</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label   I1   I2    I3    I4       I5     I6     I7    I8     I9  ...  \\\n",
       "0        1  1.0    0   1.0  -1.0    227.0    1.0  173.0  18.0   50.0  ...   \n",
       "1        1  4.0    1   1.0   2.0     27.0    2.0    4.0   2.0    2.0  ...   \n",
       "2        1  0.0  806  -1.0  -1.0   1752.0  142.0    2.0   0.0   50.0  ...   \n",
       "3        0  2.0   -1  42.0  14.0    302.0   38.0   25.0  38.0   90.0  ...   \n",
       "4        1  0.0   57   2.0   1.0   2891.0    2.0   35.0   1.0  137.0  ...   \n",
       "..     ...  ...  ...   ...   ...      ...    ...    ...   ...    ...  ...   \n",
       "395     -1  1.0    0   1.0  -1.0    149.0    5.0    1.0   0.0    0.0  ...   \n",
       "396     -1 -1.0   -1  -1.0  -1.0     -1.0   -1.0    0.0   0.0    6.0  ...   \n",
       "397     -1  0.0  300   4.0  -1.0   4622.0   25.0   20.0   6.0   55.0  ...   \n",
       "398     -1  1.0    1   2.0   1.0      5.0    1.0    1.0   1.0    1.0  ...   \n",
       "399     -1 -1.0    2  -1.0  -1.0  36144.0   -1.0   -1.0  36.0   -1.0  ...   \n",
       "\n",
       "          C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0    3486227d  e88ffc9d  c393dc22  b1252a9d  57c90cd9        -1  bcdee96c   \n",
       "1    07c540c4  92555263        -1        -1  242bb710        -1  3a171ecb   \n",
       "2    07c540c4  25c88e42  21ddcdc9  b1252a9d  a0136dd2        -1  32c7478e   \n",
       "3    e5ba7672  5aed7436  21ddcdc9  b1252a9d  c3abeb21        -1  423fab69   \n",
       "4    e5ba7672  642f2610  1d1eb838  b1252a9d  1640d50b  ad3062eb  423fab69   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  d4bb7bd8  5aed7436  d16737e3  a458ea53  edc49a33        -1  93bad2c0   \n",
       "396  2005abd1  5162930e        -1        -1  12965bb8        -1  32c7478e   \n",
       "397  8efede7f  a78bd508  21ddcdc9  5840adea  c2a93b37        -1  3a171ecb   \n",
       "398  d4bb7bd8  a1d0cc4f  c68db44a  a458ea53  3b1ae854        -1  32c7478e   \n",
       "399  e5ba7672  7b49e3d2        -1        -1  dfcfc3fa        -1  423fab69   \n",
       "\n",
       "          C24       C25       C26  \n",
       "0    4d19a3eb  cb079c2d  456c12a0  \n",
       "1    72c78f11        -1        -1  \n",
       "2    8fc66e78  001f3601  f37f3967  \n",
       "3    1793a828  e8b83407  5cef228f  \n",
       "4    45ab94c8  2bf691b1  c84c4aec  \n",
       "..        ...       ...       ...  \n",
       "395  3fdb382b  e8b83407  80dd0a5b  \n",
       "396  71292dbb        -1        -1  \n",
       "397  1793a828  e8b83407  2fede552  \n",
       "398  57e2c6c9  1575c75f  7132fed8  \n",
       "399  aee52b6f        -1        -1  \n",
       "\n",
       "[1999 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T01:06:56.773113Z",
     "start_time": "2020-09-26T01:06:56.769166Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"下面把特征列分开处理\"\"\"\n",
    "continuous_fea = ['I'+str(i+1) for i in range(13)]\n",
    "category_fea = ['C'+str(i+1) for i in range(26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T01:06:57.465039Z",
     "start_time": "2020-09-26T01:06:57.426135Z"
    }
   },
   "outputs": [],
   "source": [
    "# 类别特征编码\n",
    "lab = LabelEncoder()\n",
    "for col in category_fea:\n",
    "    data[col] = data[col].astype('str')\n",
    "    data[col] = lab.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T01:06:58.489746Z",
     "start_time": "2020-09-26T01:06:58.481768Z"
    }
   },
   "outputs": [],
   "source": [
    "# 分开\n",
    "df_train = data[:df_train.shape[0]]\n",
    "df_test = data[df_train.shape[0]:]\n",
    "del df_test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T01:06:59.630704Z",
     "start_time": "2020-09-26T01:06:59.626716Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成数据集\n",
    "x_train = df_train.drop(columns='Label')\n",
    "y_train = df_train['Label'].values\n",
    "x_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T01:07:00.603657Z",
     "start_time": "2020-09-26T01:07:00.593686Z"
    }
   },
   "outputs": [],
   "source": [
    "# 标准化\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T14:34:51.017307Z",
     "start_time": "2020-09-25T14:34:50.997360Z"
    }
   },
   "outputs": [],
   "source": [
    "# 转换格式\n",
    "x_train = [{v: k for k, v in zip(i, range(len(i)))} for i in x_train]\n",
    "x_test = [{v: k for k, v in zip(i, range(len(i)))} for i in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T14:34:52.129097Z",
     "start_time": "2020-09-25T14:34:52.125107Z"
    }
   },
   "outputs": [],
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T14:35:18.042798Z",
     "start_time": "2020-09-25T14:35:17.988560Z"
    }
   },
   "outputs": [],
   "source": [
    "# 这里需要进行转换一下才能用这个包\n",
    "v = DictVectorizer()\n",
    "x_tr = v.fit_transform(x_tr)\n",
    "x_val = v.transform(x_val)\n",
    "x_test = v.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T14:35:19.632540Z",
     "start_time": "2020-09-25T14:35:19.629548Z"
    }
   },
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "fm = pylibfm.FM(num_factors=200, num_iter=100, verbose=True, task='classification', initial_learning_rate=0.001, learning_rate_schedule='optimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T14:44:08.854402Z",
     "start_time": "2020-09-25T14:35:26.854087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training log loss: 0.53971\n",
      "-- Epoch 2\n",
      "Training log loss: 0.52317\n",
      "-- Epoch 3\n",
      "Training log loss: 0.51469\n",
      "-- Epoch 4\n",
      "Training log loss: 0.50653\n",
      "-- Epoch 5\n",
      "Training log loss: 0.50321\n",
      "-- Epoch 6\n",
      "Training log loss: 0.49856\n",
      "-- Epoch 7\n",
      "Training log loss: 0.49682\n",
      "-- Epoch 8\n",
      "Training log loss: 0.49321\n",
      "-- Epoch 9\n",
      "Training log loss: 0.49154\n",
      "-- Epoch 10\n",
      "Training log loss: 0.48990\n",
      "-- Epoch 11\n",
      "Training log loss: 0.48766\n",
      "-- Epoch 12\n",
      "Training log loss: 0.48649\n",
      "-- Epoch 13\n",
      "Training log loss: 0.48378\n",
      "-- Epoch 14\n",
      "Training log loss: 0.48180\n",
      "-- Epoch 15\n",
      "Training log loss: 0.47986\n",
      "-- Epoch 16\n",
      "Training log loss: 0.47894\n",
      "-- Epoch 17\n",
      "Training log loss: 0.47656\n",
      "-- Epoch 18\n",
      "Training log loss: 0.47654\n",
      "-- Epoch 19\n",
      "Training log loss: 0.47287\n",
      "-- Epoch 20\n",
      "Training log loss: 0.47443\n",
      "-- Epoch 21\n",
      "Training log loss: 0.47296\n",
      "-- Epoch 22\n",
      "Training log loss: 0.47111\n",
      "-- Epoch 23\n",
      "Training log loss: 0.46953\n",
      "-- Epoch 24\n",
      "Training log loss: 0.46927\n",
      "-- Epoch 25\n",
      "Training log loss: 0.46737\n",
      "-- Epoch 26\n",
      "Training log loss: 0.46719\n",
      "-- Epoch 27\n",
      "Training log loss: 0.46644\n",
      "-- Epoch 28\n",
      "Training log loss: 0.46390\n",
      "-- Epoch 29\n",
      "Training log loss: 0.46423\n",
      "-- Epoch 30\n",
      "Training log loss: 0.46186\n",
      "-- Epoch 31\n",
      "Training log loss: 0.46209\n",
      "-- Epoch 32\n",
      "Training log loss: 0.46016\n",
      "-- Epoch 33\n",
      "Training log loss: 0.45951\n",
      "-- Epoch 34\n",
      "Training log loss: 0.46001\n",
      "-- Epoch 35\n",
      "Training log loss: 0.45847\n",
      "-- Epoch 36\n",
      "Training log loss: 0.45674\n",
      "-- Epoch 37\n",
      "Training log loss: 0.45477\n",
      "-- Epoch 38\n",
      "Training log loss: 0.45699\n",
      "-- Epoch 39\n",
      "Training log loss: 0.45564\n",
      "-- Epoch 40\n",
      "Training log loss: 0.45529\n",
      "-- Epoch 41\n",
      "Training log loss: 0.45408\n",
      "-- Epoch 42\n",
      "Training log loss: 0.45224\n",
      "-- Epoch 43\n",
      "Training log loss: 0.45292\n",
      "-- Epoch 44\n",
      "Training log loss: 0.45277\n",
      "-- Epoch 45\n",
      "Training log loss: 0.45111\n",
      "-- Epoch 46\n",
      "Training log loss: 0.44646\n",
      "-- Epoch 47\n",
      "Training log loss: 0.44904\n",
      "-- Epoch 48\n",
      "Training log loss: 0.44920\n",
      "-- Epoch 49\n",
      "Training log loss: 0.44769\n",
      "-- Epoch 50\n",
      "Training log loss: 0.44798\n",
      "-- Epoch 51\n",
      "Training log loss: 0.44654\n",
      "-- Epoch 52\n",
      "Training log loss: 0.44657\n",
      "-- Epoch 53\n",
      "Training log loss: 0.44507\n",
      "-- Epoch 54\n",
      "Training log loss: 0.44426\n",
      "-- Epoch 55\n",
      "Training log loss: 0.44396\n",
      "-- Epoch 56\n",
      "Training log loss: 0.44397\n",
      "-- Epoch 57\n",
      "Training log loss: 0.44283\n",
      "-- Epoch 58\n",
      "Training log loss: 0.44399\n",
      "-- Epoch 59\n",
      "Training log loss: 0.44277\n",
      "-- Epoch 60\n",
      "Training log loss: 0.44163\n",
      "-- Epoch 61\n",
      "Training log loss: 0.44231\n",
      "-- Epoch 62\n",
      "Training log loss: 0.44006\n",
      "-- Epoch 63\n",
      "Training log loss: 0.44179\n",
      "-- Epoch 64\n",
      "Training log loss: 0.43797\n",
      "-- Epoch 65\n",
      "Training log loss: 0.44046\n",
      "-- Epoch 66\n",
      "Training log loss: 0.43829\n",
      "-- Epoch 67\n",
      "Training log loss: 0.43960\n",
      "-- Epoch 68\n",
      "Training log loss: 0.43860\n",
      "-- Epoch 69\n",
      "Training log loss: 0.43670\n",
      "-- Epoch 70\n",
      "Training log loss: 0.43702\n",
      "-- Epoch 71\n",
      "Training log loss: 0.43710\n",
      "-- Epoch 72\n",
      "Training log loss: 0.43484\n",
      "-- Epoch 73\n",
      "Training log loss: 0.43722\n",
      "-- Epoch 74\n",
      "Training log loss: 0.43584\n",
      "-- Epoch 75\n",
      "Training log loss: 0.43601\n",
      "-- Epoch 76\n",
      "Training log loss: 0.43442\n",
      "-- Epoch 77\n",
      "Training log loss: 0.43484\n",
      "-- Epoch 78\n",
      "Training log loss: 0.43375\n",
      "-- Epoch 79\n",
      "Training log loss: 0.43406\n",
      "-- Epoch 80\n",
      "Training log loss: 0.43244\n",
      "-- Epoch 81\n",
      "Training log loss: 0.43240\n",
      "-- Epoch 82\n",
      "Training log loss: 0.43237\n",
      "-- Epoch 83\n",
      "Training log loss: 0.43382\n",
      "-- Epoch 84\n",
      "Training log loss: 0.43245\n",
      "-- Epoch 85\n",
      "Training log loss: 0.43159\n",
      "-- Epoch 86\n",
      "Training log loss: 0.43076\n",
      "-- Epoch 87\n",
      "Training log loss: 0.43191\n",
      "-- Epoch 88\n",
      "Training log loss: 0.42978\n",
      "-- Epoch 89\n",
      "Training log loss: 0.42982\n",
      "-- Epoch 90\n",
      "Training log loss: 0.43038\n",
      "-- Epoch 91\n",
      "Training log loss: 0.42950\n",
      "-- Epoch 92\n",
      "Training log loss: 0.42896\n",
      "-- Epoch 93\n",
      "Training log loss: 0.42890\n",
      "-- Epoch 94\n",
      "Training log loss: 0.42843\n",
      "-- Epoch 95\n",
      "Training log loss: 0.42924\n",
      "-- Epoch 96\n",
      "Training log loss: 0.42708\n",
      "-- Epoch 97\n",
      "Training log loss: 0.42831\n",
      "-- Epoch 98\n",
      "Training log loss: 0.42811\n",
      "-- Epoch 99\n",
      "Training log loss: 0.42682\n",
      "-- Epoch 100\n",
      "Training log loss: 0.42791\n"
     ]
    }
   ],
   "source": [
    "fm.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T14:44:09.289471Z",
     "start_time": "2020-09-25T14:44:09.250535Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pre = fm.predict(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T14:44:09.686367Z",
     "start_time": "2020-09-25T14:44:09.675400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4247870594982894"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_tr, train_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T14:44:10.063359Z",
     "start_time": "2020-09-25T14:44:10.050394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4677241466075124"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pre = fm.predict(x_val)\n",
    "log_loss(y_val, val_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 造轮子版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:47:54.918607Z",
     "start_time": "2020-09-25T23:47:54.914617Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入包\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T00:08:13.347635Z",
     "start_time": "2020-09-26T00:08:13.342649Z"
    }
   },
   "outputs": [],
   "source": [
    "# dense特征取对数， sparse特征类别编码\n",
    "def process_feat(data, dense_feats, sparse_feats):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # dense\n",
    "    df_dense = df[dense_feats].fillna(0.0)\n",
    "    for f in tqdm(dense_feats):\n",
    "        df_dense[f] = df_dense[f].apply(lambda x: np.log(1+x) if x > -1 else -1)\n",
    "        \n",
    "    # sparse\n",
    "    df_sparse = df[sparse_feats].fillna('-1')\n",
    "    for f in tqdm(sparse_feats):\n",
    "        lbe = LabelEncoder()\n",
    "        df_sparse[f] = lbe.fit_transform(df_sparse[f])\n",
    "    \n",
    "    df_new = pd.concat([df_dense, df_sparse], axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T00:10:40.496072Z",
     "start_time": "2020-09-26T00:10:40.486098Z"
    }
   },
   "outputs": [],
   "source": [
    "# FM 特征组合层\n",
    "class crossLayer(layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim=10, **kwargs):\n",
    "        super(crossLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # 定义交叉特征的权重\n",
    "        self.kernel = self.add_weight(name='kernel', shape=(self.input_dim, self.output_dim), initializer='glorot_uniform', trainable=True)\n",
    "    \n",
    "    def call(self, x): # 对照上述公式中的二次项优化公式理解\n",
    "        a = K.pow(K.dot(x, self.kernel), 2)\n",
    "        b = K.dot(K.pow(x, 2), K.pow(self.kernel, 2))\n",
    "        return 0.5 * K.mean(a-b, 1, keepdims=True)\n",
    "    \n",
    "# 定义FM模型\n",
    "def FM(feature_dim):\n",
    "    inputs = Input(shape=(feature_dim, ))\n",
    "    \n",
    "    # 一阶特征\n",
    "    linear = Dense(units=1, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01))(inputs)\n",
    "    \n",
    "    # 二阶特征\n",
    "    cross = crossLayer(feature_dim)(inputs)\n",
    "    add = Add()([linear, cross])            # 将一阶特征与二阶特征相加构建FM模型\n",
    "    \n",
    "    pred = Activation('sigmoid')(add)\n",
    "    model = Model(inputs=inputs, outputs=pred)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(), metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T00:06:47.474684Z",
     "start_time": "2020-09-26T00:06:47.453741Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读入数据\n",
    "path = 'criteo/'\n",
    "data = pd.read_csv(path + 'train.csv')\n",
    "\n",
    "# 去掉id列， 把测试集和训练集合并， 填充缺失值\n",
    "data.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T00:08:19.070308Z",
     "start_time": "2020-09-26T00:08:18.989516Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 362.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 1086.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# dense 特征开头是I, sparse特征开头是C， label是标签\n",
    "cols = data.columns.values\n",
    "\n",
    "dense_feats = [f for f in cols if f[0] == 'I']\n",
    "sparse_feats = [f for f in cols if f[0] == 'C']\n",
    "\n",
    "# 数据预处理\n",
    "feats = process_feat(data, dense_feats, sparse_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T00:09:36.035839Z",
     "start_time": "2020-09-26T00:09:36.029898Z"
    }
   },
   "outputs": [],
   "source": [
    "# 划分训练和验证数据\n",
    "x_trn, x_tst, y_trn, y_tst = train_test_split(feats, data['Label'], test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T00:10:42.862765Z",
     "start_time": "2020-09-26T00:10:42.677896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ZhongqiangWu\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "model = FM(feats.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T00:11:38.117432Z",
     "start_time": "2020-09-26T00:11:33.462768Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1279 samples, validate on 320 samples\n",
      "Epoch 1/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.5410 - binary_accuracy: 0.718 - 0s 33us/sample - loss: 3.8134 - binary_accuracy: 0.7639 - val_loss: 3.2264 - val_binary_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.9037 - binary_accuracy: 0.820 - 0s 34us/sample - loss: 3.8130 - binary_accuracy: 0.7639 - val_loss: 3.2261 - val_binary_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6589 - binary_accuracy: 0.773 - 0s 34us/sample - loss: 3.8127 - binary_accuracy: 0.7639 - val_loss: 3.2258 - val_binary_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 5.0437 - binary_accuracy: 0.687 - 0s 30us/sample - loss: 3.8124 - binary_accuracy: 0.7639 - val_loss: 3.2255 - val_binary_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.7828 - binary_accuracy: 0.765 - 0s 33us/sample - loss: 3.8121 - binary_accuracy: 0.7639 - val_loss: 3.2252 - val_binary_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.2821 - binary_accuracy: 0.734 - 0s 31us/sample - loss: 3.8118 - binary_accuracy: 0.7639 - val_loss: 3.2249 - val_binary_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.4133 - binary_accuracy: 0.726 - 0s 29us/sample - loss: 3.8116 - binary_accuracy: 0.7639 - val_loss: 3.2247 - val_binary_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.4084 - binary_accuracy: 0.789 - 0s 35us/sample - loss: 3.8113 - binary_accuracy: 0.7639 - val_loss: 3.2244 - val_binary_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.4142 - binary_accuracy: 0.726 - 0s 31us/sample - loss: 3.8111 - binary_accuracy: 0.7639 - val_loss: 3.2242 - val_binary_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1621 - binary_accuracy: 0.742 - 0s 35us/sample - loss: 3.8109 - binary_accuracy: 0.7639 - val_loss: 3.2240 - val_binary_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.8999 - binary_accuracy: 0.820 - 0s 30us/sample - loss: 3.8107 - binary_accuracy: 0.7639 - val_loss: 3.2238 - val_binary_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0344 - binary_accuracy: 0.750 - 0s 30us/sample - loss: 3.8105 - binary_accuracy: 0.7639 - val_loss: 3.2236 - val_binary_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9069 - binary_accuracy: 0.757 - 0s 30us/sample - loss: 3.8103 - binary_accuracy: 0.7639 - val_loss: 3.2235 - val_binary_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.4118 - binary_accuracy: 0.726 - 0s 33us/sample - loss: 3.8102 - binary_accuracy: 0.7639 - val_loss: 3.2233 - val_binary_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.5302 - binary_accuracy: 0.781 - 0s 34us/sample - loss: 3.8100 - binary_accuracy: 0.7639 - val_loss: 3.2232 - val_binary_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.0277 - binary_accuracy: 0.812 - 0s 30us/sample - loss: 3.8099 - binary_accuracy: 0.7639 - val_loss: 3.2230 - val_binary_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.5299 - binary_accuracy: 0.781 - 0s 31us/sample - loss: 3.8097 - binary_accuracy: 0.7639 - val_loss: 3.2229 - val_binary_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1580 - binary_accuracy: 0.742 - 0s 32us/sample - loss: 3.8096 - binary_accuracy: 0.7639 - val_loss: 3.2228 - val_binary_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.7843 - binary_accuracy: 0.765 - 0s 34us/sample - loss: 3.8095 - binary_accuracy: 0.7639 - val_loss: 3.2227 - val_binary_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.4110 - binary_accuracy: 0.726 - 0s 34us/sample - loss: 3.8094 - binary_accuracy: 0.7639 - val_loss: 3.2226 - val_binary_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.7799 - binary_accuracy: 0.765 - 0s 30us/sample - loss: 3.8093 - binary_accuracy: 0.7639 - val_loss: 3.2225 - val_binary_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.8983 - binary_accuracy: 0.820 - 0s 32us/sample - loss: 3.8092 - binary_accuracy: 0.7639 - val_loss: 3.2224 - val_binary_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.7723 - binary_accuracy: 0.828 - 0s 30us/sample - loss: 3.8091 - binary_accuracy: 0.7639 - val_loss: 3.2223 - val_binary_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.5305 - binary_accuracy: 0.781 - 0s 34us/sample - loss: 3.8090 - binary_accuracy: 0.7639 - val_loss: 3.2222 - val_binary_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 5.0401 - binary_accuracy: 0.687 - 0s 36us/sample - loss: 3.8089 - binary_accuracy: 0.7639 - val_loss: 3.2221 - val_binary_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.9169 - binary_accuracy: 0.695 - 0s 36us/sample - loss: 3.8088 - binary_accuracy: 0.7639 - val_loss: 3.2220 - val_binary_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0312 - binary_accuracy: 0.750 - 0s 34us/sample - loss: 3.8087 - binary_accuracy: 0.7639 - val_loss: 3.2220 - val_binary_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6561 - binary_accuracy: 0.773 - 0s 32us/sample - loss: 3.8087 - binary_accuracy: 0.7639 - val_loss: 3.2219 - val_binary_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6574 - binary_accuracy: 0.773 - 0s 34us/sample - loss: 3.8086 - binary_accuracy: 0.7639 - val_loss: 3.2218 - val_binary_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.2884 - binary_accuracy: 0.734 - 0s 31us/sample - loss: 3.8085 - binary_accuracy: 0.7639 - val_loss: 3.2218 - val_binary_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0323 - binary_accuracy: 0.750 - 0s 33us/sample - loss: 3.8085 - binary_accuracy: 0.7639 - val_loss: 3.2217 - val_binary_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.1522 - binary_accuracy: 0.804 - 0s 32us/sample - loss: 3.8084 - binary_accuracy: 0.7639 - val_loss: 3.2217 - val_binary_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.5285 - binary_accuracy: 0.781 - 0s 32us/sample - loss: 3.8084 - binary_accuracy: 0.7639 - val_loss: 3.2216 - val_binary_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1567 - binary_accuracy: 0.742 - 0s 30us/sample - loss: 3.8083 - binary_accuracy: 0.7639 - val_loss: 3.2216 - val_binary_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1594 - binary_accuracy: 0.742 - 0s 31us/sample - loss: 3.8083 - binary_accuracy: 0.7639 - val_loss: 3.2215 - val_binary_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.9001 - binary_accuracy: 0.820 - 0s 35us/sample - loss: 3.8082 - binary_accuracy: 0.7639 - val_loss: 3.2215 - val_binary_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 5.0353 - binary_accuracy: 0.687 - 0s 31us/sample - loss: 3.8082 - binary_accuracy: 0.7639 - val_loss: 3.2214 - val_binary_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.7788 - binary_accuracy: 0.765 - 0s 31us/sample - loss: 3.8081 - binary_accuracy: 0.7639 - val_loss: 3.2214 - val_binary_accuracy: 0.8000\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279/1279 [==============================] - ETA: 0s - loss: 3.5310 - binary_accuracy: 0.781 - 0s 31us/sample - loss: 3.8081 - binary_accuracy: 0.7639 - val_loss: 3.2213 - val_binary_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0347 - binary_accuracy: 0.750 - 0s 32us/sample - loss: 3.8081 - binary_accuracy: 0.7639 - val_loss: 3.2213 - val_binary_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 5.0393 - binary_accuracy: 0.687 - 0s 32us/sample - loss: 3.8080 - binary_accuracy: 0.7639 - val_loss: 3.2213 - val_binary_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.4022 - binary_accuracy: 0.789 - 0s 31us/sample - loss: 3.8080 - binary_accuracy: 0.7639 - val_loss: 3.2212 - val_binary_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.7786 - binary_accuracy: 0.765 - 0s 34us/sample - loss: 3.8080 - binary_accuracy: 0.7639 - val_loss: 3.2212 - val_binary_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9072 - binary_accuracy: 0.757 - 0s 33us/sample - loss: 3.8079 - binary_accuracy: 0.7639 - val_loss: 3.2212 - val_binary_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9003 - binary_accuracy: 0.757 - 0s 36us/sample - loss: 3.8079 - binary_accuracy: 0.7639 - val_loss: 3.2211 - val_binary_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6553 - binary_accuracy: 0.773 - ETA: 0s - loss: 3.8214 - binary_accuracy: 0.763 - 0s 87us/sample - loss: 3.8079 - binary_accuracy: 0.7639 - val_loss: 3.2211 - val_binary_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.6627 - binary_accuracy: 0.710 - 0s 30us/sample - loss: 3.8078 - binary_accuracy: 0.7639 - val_loss: 3.2211 - val_binary_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.7812 - binary_accuracy: 0.765 - 0s 34us/sample - loss: 3.8078 - binary_accuracy: 0.7639 - val_loss: 3.2210 - val_binary_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1589 - binary_accuracy: 0.742 - 0s 34us/sample - loss: 3.8078 - binary_accuracy: 0.7639 - val_loss: 3.2210 - val_binary_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0330 - binary_accuracy: 0.750 - 0s 35us/sample - loss: 3.8077 - binary_accuracy: 0.7639 - val_loss: 3.2210 - val_binary_accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.6543 - binary_accuracy: 0.710 - 0s 31us/sample - loss: 3.8077 - binary_accuracy: 0.7639 - val_loss: 3.2210 - val_binary_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6565 - binary_accuracy: 0.773 - 0s 33us/sample - loss: 3.8077 - binary_accuracy: 0.7639 - val_loss: 3.2209 - val_binary_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9042 - binary_accuracy: 0.757 - 0s 34us/sample - loss: 3.8077 - binary_accuracy: 0.7639 - val_loss: 3.2209 - val_binary_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.1500 - binary_accuracy: 0.804 - 0s 34us/sample - loss: 3.8076 - binary_accuracy: 0.7639 - val_loss: 3.2209 - val_binary_accuracy: 0.8000\n",
      "Epoch 55/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.0268 - binary_accuracy: 0.812 - 0s 33us/sample - loss: 3.8076 - binary_accuracy: 0.7639 - val_loss: 3.2208 - val_binary_accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6550 - binary_accuracy: 0.773 - 0s 30us/sample - loss: 3.8076 - binary_accuracy: 0.7639 - val_loss: 3.2208 - val_binary_accuracy: 0.8000\n",
      "Epoch 57/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.1499 - binary_accuracy: 0.804 - 0s 31us/sample - loss: 3.8075 - binary_accuracy: 0.7639 - val_loss: 3.2208 - val_binary_accuracy: 0.8000\n",
      "Epoch 58/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.8994 - binary_accuracy: 0.820 - 0s 29us/sample - loss: 3.8075 - binary_accuracy: 0.7639 - val_loss: 3.2208 - val_binary_accuracy: 0.8000\n",
      "Epoch 59/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.2818 - binary_accuracy: 0.734 - 0s 32us/sample - loss: 3.8075 - binary_accuracy: 0.7639 - val_loss: 3.2207 - val_binary_accuracy: 0.8000\n",
      "Epoch 60/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0286 - binary_accuracy: 0.750 - 0s 41us/sample - loss: 3.8075 - binary_accuracy: 0.7639 - val_loss: 3.2207 - val_binary_accuracy: 0.8000\n",
      "Epoch 61/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9067 - binary_accuracy: 0.757 - 0s 35us/sample - loss: 3.8074 - binary_accuracy: 0.7639 - val_loss: 3.2207 - val_binary_accuracy: 0.8000\n",
      "Epoch 62/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1613 - binary_accuracy: 0.742 - 0s 30us/sample - loss: 3.8074 - binary_accuracy: 0.7639 - val_loss: 3.2207 - val_binary_accuracy: 0.8000\n",
      "Epoch 63/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.2757 - binary_accuracy: 0.796 - 0s 28us/sample - loss: 3.8074 - binary_accuracy: 0.7639 - val_loss: 3.2206 - val_binary_accuracy: 0.8000\n",
      "Epoch 64/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0298 - binary_accuracy: 0.750 - 0s 29us/sample - loss: 3.8074 - binary_accuracy: 0.7639 - val_loss: 3.2206 - val_binary_accuracy: 0.8000\n",
      "Epoch 65/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.4002 - binary_accuracy: 0.789 - 0s 27us/sample - loss: 3.8073 - binary_accuracy: 0.7639 - val_loss: 3.2206 - val_binary_accuracy: 0.8000\n",
      "Epoch 66/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0325 - binary_accuracy: 0.750 - 0s 29us/sample - loss: 3.8073 - binary_accuracy: 0.7639 - val_loss: 3.2206 - val_binary_accuracy: 0.8000\n",
      "Epoch 67/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.7793 - binary_accuracy: 0.765 - 0s 29us/sample - loss: 3.8073 - binary_accuracy: 0.7639 - val_loss: 3.2205 - val_binary_accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.0251 - binary_accuracy: 0.812 - 0s 30us/sample - loss: 3.8073 - binary_accuracy: 0.7639 - val_loss: 3.2205 - val_binary_accuracy: 0.8000\n",
      "Epoch 69/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0270 - binary_accuracy: 0.750 - 0s 29us/sample - loss: 3.8073 - binary_accuracy: 0.7639 - val_loss: 3.2205 - val_binary_accuracy: 0.8000\n",
      "Epoch 70/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.2695 - binary_accuracy: 0.859 - 0s 33us/sample - loss: 3.8072 - binary_accuracy: 0.7639 - val_loss: 3.2205 - val_binary_accuracy: 0.8000\n",
      "Epoch 71/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.2769 - binary_accuracy: 0.796 - 0s 30us/sample - loss: 3.8072 - binary_accuracy: 0.7639 - val_loss: 3.2204 - val_binary_accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.6579 - binary_accuracy: 0.710 - 0s 32us/sample - loss: 3.8072 - binary_accuracy: 0.7639 - val_loss: 3.2204 - val_binary_accuracy: 0.8000\n",
      "Epoch 73/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.5287 - binary_accuracy: 0.781 - 0s 30us/sample - loss: 3.8072 - binary_accuracy: 0.7639 - val_loss: 3.2204 - val_binary_accuracy: 0.8000\n",
      "Epoch 74/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6518 - binary_accuracy: 0.773 - 0s 30us/sample - loss: 3.8071 - binary_accuracy: 0.7639 - val_loss: 3.2204 - val_binary_accuracy: 0.8000\n",
      "Epoch 75/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1555 - binary_accuracy: 0.742 - 0s 30us/sample - loss: 3.8071 - binary_accuracy: 0.7639 - val_loss: 3.2204 - val_binary_accuracy: 0.8000\n",
      "Epoch 76/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9036 - binary_accuracy: 0.757 - 0s 31us/sample - loss: 3.8071 - binary_accuracy: 0.7639 - val_loss: 3.2203 - val_binary_accuracy: 0.8000\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6531 - binary_accuracy: 0.773 - 0s 30us/sample - loss: 3.8071 - binary_accuracy: 0.7639 - val_loss: 3.2203 - val_binary_accuracy: 0.8000\n",
      "Epoch 78/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.7837 - binary_accuracy: 0.703 - 0s 30us/sample - loss: 3.8070 - binary_accuracy: 0.7639 - val_loss: 3.2203 - val_binary_accuracy: 0.8000\n",
      "Epoch 79/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.5299 - binary_accuracy: 0.781 - 0s 28us/sample - loss: 3.8070 - binary_accuracy: 0.7639 - val_loss: 3.2203 - val_binary_accuracy: 0.8000\n",
      "Epoch 80/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1581 - binary_accuracy: 0.742 - 0s 32us/sample - loss: 3.8070 - binary_accuracy: 0.7639 - val_loss: 3.2202 - val_binary_accuracy: 0.8000\n",
      "Epoch 81/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.7850 - binary_accuracy: 0.703 - 0s 28us/sample - loss: 3.8070 - binary_accuracy: 0.7639 - val_loss: 3.2202 - val_binary_accuracy: 0.8000\n",
      "Epoch 82/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1526 - binary_accuracy: 0.742 - 0s 30us/sample - loss: 3.8069 - binary_accuracy: 0.7639 - val_loss: 3.2202 - val_binary_accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.1567 - binary_accuracy: 0.742 - 0s 30us/sample - loss: 3.8069 - binary_accuracy: 0.7639 - val_loss: 3.2202 - val_binary_accuracy: 0.8000\n",
      "Epoch 84/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9076 - binary_accuracy: 0.757 - 0s 30us/sample - loss: 3.8069 - binary_accuracy: 0.7639 - val_loss: 3.2201 - val_binary_accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 5.6691 - binary_accuracy: 0.648 - 0s 29us/sample - loss: 3.8069 - binary_accuracy: 0.7639 - val_loss: 3.2201 - val_binary_accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6515 - binary_accuracy: 0.773 - 0s 28us/sample - loss: 3.8068 - binary_accuracy: 0.7639 - val_loss: 3.2201 - val_binary_accuracy: 0.8000\n",
      "Epoch 87/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.7802 - binary_accuracy: 0.765 - 0s 29us/sample - loss: 3.8068 - binary_accuracy: 0.7639 - val_loss: 3.2201 - val_binary_accuracy: 0.8000\n",
      "Epoch 88/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.5270 - binary_accuracy: 0.781 - 0s 28us/sample - loss: 3.8068 - binary_accuracy: 0.7639 - val_loss: 3.2200 - val_binary_accuracy: 0.8000\n",
      "Epoch 89/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.0320 - binary_accuracy: 0.750 - 0s 29us/sample - loss: 3.8068 - binary_accuracy: 0.7639 - val_loss: 3.2200 - val_binary_accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 5.2884 - binary_accuracy: 0.671 - 0s 28us/sample - loss: 3.8068 - binary_accuracy: 0.7639 - val_loss: 3.2200 - val_binary_accuracy: 0.8000\n",
      "Epoch 91/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.9093 - binary_accuracy: 0.695 - 0s 29us/sample - loss: 3.8067 - binary_accuracy: 0.7639 - val_loss: 3.2200 - val_binary_accuracy: 0.8000\n",
      "Epoch 92/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.4037 - binary_accuracy: 0.789 - 0s 29us/sample - loss: 3.8067 - binary_accuracy: 0.7639 - val_loss: 3.2200 - val_binary_accuracy: 0.8000\n",
      "Epoch 93/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.4069 - binary_accuracy: 0.726 - 0s 30us/sample - loss: 3.8067 - binary_accuracy: 0.7639 - val_loss: 3.2199 - val_binary_accuracy: 0.8000\n",
      "Epoch 94/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9046 - binary_accuracy: 0.757 - 0s 28us/sample - loss: 3.8067 - binary_accuracy: 0.7639 - val_loss: 3.2199 - val_binary_accuracy: 0.8000\n",
      "Epoch 95/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.7786 - binary_accuracy: 0.765 - 0s 27us/sample - loss: 3.8066 - binary_accuracy: 0.7639 - val_loss: 3.2199 - val_binary_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.5295 - binary_accuracy: 0.781 - 0s 28us/sample - loss: 3.8066 - binary_accuracy: 0.7639 - val_loss: 3.2199 - val_binary_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.6554 - binary_accuracy: 0.773 - 0s 27us/sample - loss: 3.8066 - binary_accuracy: 0.7639 - val_loss: 3.2198 - val_binary_accuracy: 0.8000\n",
      "Epoch 98/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 4.2823 - binary_accuracy: 0.734 - 0s 27us/sample - loss: 3.8066 - binary_accuracy: 0.7639 - val_loss: 3.2198 - val_binary_accuracy: 0.8000\n",
      "Epoch 99/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9003 - binary_accuracy: 0.757 - 0s 29us/sample - loss: 3.8065 - binary_accuracy: 0.7639 - val_loss: 3.2198 - val_binary_accuracy: 0.8000\n",
      "Epoch 100/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 3.9003 - binary_accuracy: 0.757 - 0s 30us/sample - loss: 3.8065 - binary_accuracy: 0.7639 - val_loss: 3.2198 - val_binary_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x184748251d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, epochs=100, batch_size=128, validation_data=(x_tst, y_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T00:12:08.891853Z",
     "start_time": "2020-09-26T00:12:08.838000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预测\n",
    "y_pred = model.predict(x_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T00:12:14.325980Z",
     "start_time": "2020-09-26T00:12:14.317005Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
