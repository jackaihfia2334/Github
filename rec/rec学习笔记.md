# 推荐系统入门

## 一、概述

### 推荐系统意义

个性化推荐系统通过分析用户的行为日志，得到用户当前的甚至未来可能的兴趣，给不同的用户展示不同的(个性化)的页面，来提高网站或者app的点击率、转化率、留存率等指标。

搜索和推荐都是解决互联网大数据时代信息过载的手段，但是它们也存在着许多的不同：

用户意图；个性化程度；优化目标；马太效应和长尾理论；



### 推荐系统架构

<u>架构设计的核心在于平衡和妥协</u>

思考推荐系统架构考虑的第一个问题是**确定边界**：知道推荐系统要负责哪部分问题，这就是边界内的部分。在这个基础上，架构要分为哪几个部分，每一部分需要完成的子功能是什么，每一部分依赖外界的什么。

**系统架构：**

设计思想是大数据背景下如何有效利用海量和实时数据，将推荐系统按照对数据利用情况和系统响应要求出发，将整个架构分为**离线层、近线层、在线层**三个模块。系统架构是如何权衡利弊，如何利用各种技术工具帮助我们达到想要的目的的，方便我们理解为什么推荐系统要这样设计。

离线层对于数据数量和算法复杂度限制更少，没有很强的时间要求。由于没有及时加入最新的数据，所以很容易过时。在线层能更快地响应最近的事件和用户交互，但必须实时完成，这会限制使用算法的复杂性和处理的数据量。近线层介于两种方法之间。

1. 离线层：不用实时数据，不提供实时响应；
2. 近线层：使用实时数据，不保证实时响应；
3. 在线层：使用实时数据，保证实时在线服务；

![在这里插入图片描述](http://ryluo.oss-cn-chengdu.aliyuncs.com/%E5%9B%BE%E7%89%87image-20220409204658032.png)

整个数据部分其实是一整个链路，主要是三块：

客户端及服务器实时数据处理：记录实时数据；流处理平台准实时数据处理：记录准实时数据，在推荐领域基本上只有一个类别，就是用户行为数据；大数据平台离线数据处理：所有“脏活累活”复杂的操作都是在离线完成的。



**算法架构：**

**召回、粗排、排序、重排**等算法环节角度出发的，重要的是要去理解每个环节需要完成的任务，每个环节的评价体系，以及为什么要那么设计。还有一个重要问题是每个环节涉及到的技术栈和主流算法。这种角度来看是把推荐系统从前往后串起来，**其中每一个模块既有在离线层工作的，也有在在线层工作的**。

![在这里插入图片描述](http://ryluo.oss-cn-chengdu.aliyuncs.com/%E5%9B%BE%E7%89%87image-20220409211354342.png)

召回阶段我们现在主要是在保证Item质量的基础上注重覆盖率多样性，粗排阶段主要用简单的模型来解决不同路的召回和当前用户的相关性问题，最后截断到1k个以内的候选集。

粗排的原因是有时候召回的结果还是太多，精排层速度还是跟不上，所以加入粗排。粗排可以理解为精排前的一轮过滤机制，减轻精排模块的压力。粗排介于召回和精排之间，要同时兼顾精准性和低延迟。

精排是推荐系统各层级中最纯粹的一层，他的目标比较单一且集中，一门心思的实现目标的调优即可。解决样本规模和时效性问题。

重排序阶段对精排生成的Top-N个物品的序列进行重新排序，生成一个Top-K个物品的序列，作为排序系统最后的结果，直接展现给用户。重排序的原因是因为多个物品之间往往是相互影响的，而精排序是根据PointWise得分，容易造成推荐结果同质化严重，有很多冗余信息。

**常见的有三种优化目标：Point Wise、Pair Wise 和 List Wise。**





### 推荐系统技术栈

完整的一套推荐系统体系里，不仅会涉及到推荐算法工程师、后台开发工程师、数据挖掘/分析工程师、NLP/CV工程师还有前端、客户端甚至产品、运营等支持。作为算法工程师，需要掌握的技术栈主要就是**算法和工程**。

#### 算法：

**召回**：轻量快速低延迟，不需要十分准确，但不可遗漏。**粗排**：介于召回和精排之间，要同时兼顾精准性和低延迟。一般模型也不能过于复杂。**精排**：在最大时延允许的情况下，保证精确性。精排系统构建一般需要涉及样本、特征、模型三部分。**重排**：获取精排的排序结果，基于运营策略、多样性、context上下文等，进行一个微调。重排中规则比较多，但目前也有不少基于模型来提升重排效果的方案。**混排**：多个业务线都想在Feeds流中获取曝光，则需要对它们的结果进行混排。



**画像层**：算法主要体现在如何绘制一个用户画像和商品画像。用户画像是大家比较容易理解的，比如用户年龄、爱好通常APP会通过注册界面收集这些信息内容画像各家的做法也不同，当前比较主流的都会涉及到一个**多模态信息内容理解**。一般推荐系统会加入多模态的一个内容理解。

。。。。。省略



#### 工程：

- **编程语言**：Python、Java（scala）、C++、sql、shell；
- **机器学习**：Tensorflow/Pytorch、GraphLab/GraphCHI、LGB/Xgboost、SKLearn；
- **数据分析**：Pandas、Numpy、Seaborn、Spark；
- 数据存储：mysql、redis、mangodb、hive、kafka、es、hbase；
- 相似计算：annoy、faiss、kgraph
- 流计算：Spark Streaming、Flink
- 分布式：Hadoop、Spark





## 二、推荐系统算法基础

### 经典召回模型

#### 算法评估

**召回率**：在模型召回预测的物品中，预测准确的物品占用户实际喜欢的物品的比例。

**精确率**：推荐的物品中，对用户准确推荐的物品占总物品的比例。

- 如要确保召回率高，一般是推荐更多的物品，期望推荐的物品中会涵盖用户喜爱的物品。而实际中，推荐的物品中用户实际喜爱的物品占少数，推荐的精确率就会很低。故同时要确保高召回率和精确率往往是矛盾的，所以实际中需要在二者之间进行权衡。

**覆盖率**：推荐系统能够推荐出来的物品占总物品集合的比例。

- 覆盖率表示最终的推荐列表中包含多大比例的物品。如果所有物品都被给推荐给至少一个用户， 那么覆盖率是100%。

**新颖度**：用推荐列表中物品的平均流行度度量推荐结果的新颖度。 如果推荐出的物品都很热门， 说明推荐的新颖度较低。



#### 协同过滤算法

##### 基本思想

根据用户之前的喜好以及其他兴趣相近的用户的选择来给用户推荐物品。

基于对用户历史行为数据的挖掘发现用户的喜好偏向， 并预测用户可能喜好的产品进行推荐。

一般是**仅仅基于用户的行为数据**（评价、购买、下载等）, 而不依赖于项的任何附加信息（物品自身特征）或者用户的任何附加信息（年龄， 性别等）

- 基于用户的协同过滤算法（UserCF）
- 基于物品的协同过滤算法（ItemCF）

重点是**计算相似度**     实现代码见jupyter notebook   **rec_test**

##### 相似性度量方法

1. **杰卡德（Jaccard）相似系数**     适用于隐式反馈数据（0-1）

2. **余弦相似度**     衡量了两个向量的夹角，夹角越小越相似   在度量文本相似度、用户相似度、物品相似度的时候都较为常用。            from sklearn.metrics.pairwise importcosine_similarity

3. **皮尔逊相关系数**  就是概率论中的相关系数，对协方差归一化得到，范围在 −1 到 1

   - 相关度量的是两个变量的变化趋势是否一致，两个随机变量是不是同增同减。
   - 不适合用作计算布尔值向量（0-1）之间相关度。

   from  scipy.stats  import  pearsonr

### UserCF算法（基于用户的协同过滤算法）

计算过程：

1.计算用户之间的相似度 2.计算用户对新物品的评分预测 3.对用户进行物品推荐

具体过程和实现代码可见  jupyter notebook   **rec_test**



存在的问题：

1.数据稀疏性

- 一个大型的电子商务推荐系统一般有非常多的物品，用户可能买的其中不到1%的物品，不同用户之间买的物品重叠性较低，导致算法无法找到一个用户的邻居，即偏好相似的用户。
- 这导致UserCF不适用于那些正反馈获取较困难的应用场景(如酒店预订， 大件物品购买等低频应用)。

2.算法扩展性

- 基于用户的协同过滤需要维护用户相似度矩阵以便快速的找出 TopN*T**o**pN* 相似用户， 该矩阵的存储开销非常大，存储空间随着用户数量的增加而增加。
- 故不适合用户数据量大的情况使用



### UserCF算法（基于用户的协同过滤算法）

ItemCF算法并不利用物品的内容属性计算物品之间的相似度， 主要通过分析用户的行为记录计算物品之间的相似度， 该算法认为， 物品 A 和物品 C 具有很大的相似度是因为喜欢物品 A 的用户极可能喜欢物品 C。

和基于内容的推荐算法(Content-Based Recommendation)进行区分！





### 协同过滤算法的问题分析

泛化能力弱：

- 即协同过滤无法将两个物品相似的信息推广到其他物品的相似性上。
- 导致的问题是**热门物品具有很强的头部效应， 容易跟大量物品产生相似， 而尾部物品由于特征向量稀疏， 导致很少被推荐**。

![图片](http://ryluo.oss-cn-chengdu.aliyuncs.com/JavaxxhHm3BAtMfsy2AV.png!thumbnail)

- 可以看出，D 是一件热门物品，其与 A、B、C 的相似度比较大。因此，推荐系统更可能将 D推荐给用过 A、B、C的用户。
- 但是，推荐系统无法找出 A,B,C之间相似性的原因是交互数据太稀疏， 缺乏相似性计算的直接数据。

所以这就是协同过滤的天然缺陷：**推荐系统头部效应明显， 处理稀疏向量的能力弱**。

为了解决这个问题， 同时增加模型的泛化能力。2006年，**矩阵分解技术(Matrix Factorization, MF**)被提出：

- 该方法在协同过滤共现矩阵的基础上， 使用**更稠密的隐向量**表示用户和物品， 挖掘用户和物品的隐含兴趣和隐含特征。
- 在一定程度上弥补协同过滤模型处理稀疏矩阵能力不足的问题。





**1.什么时候使用UserCF，什么时候使用ItemCF？为什么？**

> （1）UserCF
>
> - 由于是基于用户相似度进行推荐， 所以具备更强的社交特性， 这样的特点非常适于**用户少， 物品多， 时效性较强的场合**。
>   - 比如新闻推荐场景， 因为新闻本身兴趣点分散， 相比用户对不同新闻的兴趣偏好， 新闻的及时性，热点性往往更加重要， 所以正好适用于发现热点，跟踪热点的趋势。
>   - 另外还具有推荐新信息的能力， 更有可能发现惊喜, 因为看的是人与人的相似性, 推出来的结果可能更有惊喜，可以发现用户潜在但自己尚未察觉的兴趣爱好。
>
> （2）ItemCF
>
> - 这个更适用于兴趣变化较为稳定的应用， 更接近于个性化的推荐， 适合**物品少，用户多，用户兴趣固定持久， 物品更新速度不是太快的场合**。
> - 比如推荐艺术品， 音乐， 电影。

**2.上面介绍的相似度计算方法有什么优劣之处？**

> cosine相似度计算简单方便，一般较为常用。但是，当用户的评分数据存在 bias 时，效果往往不那么好。
>
> - 简而言之，就是不同用户评分的偏向不同。部分用户可能乐于给予好评，而部分用户习惯给予差评或者乱评分。
> - 这个时候，根据cosine 相似度计算出来的推荐结果效果会打折扣。
>
> 举例来说明，如下图（`X,Y,Z` 表示物品，`d,e,f`表示用户）：
>
> ![图片](http://ryluo.oss-cn-chengdu.aliyuncs.com/JavaWKvITKBhYOkfXrzs.png!thumbnail)
>
> - 如果使用余弦相似度进行计算，用户 d 和 e 之间较为相似。但是实际上，用户 d 和 f 之间应该更加相似。只不过由于 d 倾向于打高分，e 倾向于打低分导致二者之间的余弦相似度更高。
> - 这种情况下，可以考虑使用皮尔逊相关系数计算用户之间的相似性关系。





#### FM

**原理介绍**

https://zhuanlan.zhihu.com/p/58160982

https://tech.meituan.com/2016/03/03/deep-understanding-of-ffm-principles-and-practices.html

**实战讲解**

https://zhuanlan.zhihu.com/p/343174108

https://github.com/CastellanZhang/alphaFM
